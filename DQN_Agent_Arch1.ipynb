{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.01\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_max = 1\n",
    "        self.epsilon_decay = -0.0005 \n",
    "        self.epsilon_min = 0.00001\n",
    "        \n",
    "        self.batch_size = 32\n",
    "\n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # Initialize the value of the states tracked\n",
    "        self.states_tracked = []\n",
    "        \n",
    "        # We are going to track state [0,0,0] and action (0,2) at index 2 in the action space.\n",
    "        self.track_state = np.array(env.state_encod_arch1([0,0,0])).reshape(1, 36)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    \n",
    "    def build_model(self):\n",
    "        input_shape = self.state_size\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state, possible_actions_index, actions):\n",
    "        # get action from model using epsilon-greedy policy\n",
    "        # Decay in Îµ after each episode       \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # explore: choose a random action from the ride requests\n",
    "            return random.choice(possible_actions_index)\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state = np.array(env.state_encod_arch1(state)).reshape(1, 36)\n",
    "\n",
    "            # Use the model to predict the Q_values.\n",
    "            q_value = self.model.predict(state)\n",
    "\n",
    "            # truncate the array to only those actions that are part of the ride  requests.\n",
    "            q_vals_possible = [q_value[0][i] for i in possible_actions_index]\n",
    "\n",
    "            return possible_actions_index[np.argmax(q_vals_possible)]\n",
    "\n",
    "    def append_sample(self, state, action_index, reward, next_state, done):\n",
    "        self.memory.append((state, action_index, reward, next_state, done))\n",
    "        \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            # initialise two matrices - update_input and update_output\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))\n",
    "            actions, rewards, done = [], [], []\n",
    "            \n",
    "            # populate update_input and update_output and the lists rewards, actions, done\n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, done_boolean = mini_batch[i]\n",
    "                update_input[i] = env.state_encod_arch1(state)     \n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = env.state_encod_arch1(next_state)\n",
    "                done.append(done_boolean)\n",
    "\n",
    "            # predict the target q-values from states s\n",
    "            target = self.model.predict(update_input)\n",
    "            # target for q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "\n",
    "\n",
    "            # update the target values\n",
    "            for i in range(self.batch_size):\n",
    "                if done[i]:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else: # non-terminal state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "            # model fit\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "            \n",
    "    def save_tracking_states(self):\n",
    "        # Use the model to predict the q_value of the state we are tacking.\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        \n",
    "        # Grab the q_value of the action index that we are tracking.\n",
    "        self.states_tracked.append(q_value[0][2])\n",
    "        \n",
    "    def save_test_states(self):\n",
    "        # Use the model to predict the q_value of the state we are tacking.\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        \n",
    "        # Grab the q_value of the action index that we are tracking.\n",
    "        self.states_test.append(q_value[0][2])\n",
    "    \n",
    "    def save(self, name):\n",
    "        with open(name, 'wb') as file:  \n",
    "            pickle.dump(self.model, file,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_time = 24*30 #30 days before which car has to be recharged\n",
    "n_episodes = 15000\n",
    "m = 5\n",
    "t = 24\n",
    "d = 7\n",
    "\n",
    "# Invoke Env class\n",
    "env = CabDriver()\n",
    "action_space, state_space, state = env.reset()\n",
    "\n",
    "# Set up state and action sizes.\n",
    "state_size = m+t+d\n",
    "action_size = len(action_space)\n",
    "\n",
    "# Invoke agent class\n",
    "agent = DQNAgent(action_size=action_size, state_size=state_size)\n",
    "\n",
    "# to store rewards in each episode\n",
    "rewards_per_episode, episodes = [], []\n",
    "# Rewards for state [0,0,0] being tracked.\n",
    "rewards_init_state = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model 0\n",
      "episode 9, reward -137.0, memory_length 1400, epsilon 0.9955001547284723 total_time 730.0\n",
      "episode 19, reward -181.0, memory_length 2000, epsilon 0.9905350769930761 total_time 724.0\n",
      "episode 29, reward -172.0, memory_length 2000, epsilon 0.9855947626861951 total_time 721.0\n",
      "episode 39, reward 68.0, memory_length 2000, epsilon 0.9806790882997144 total_time 722.0\n",
      "episode 49, reward -245.0, memory_length 2000, epsilon 0.9757879309415182 total_time 725.0\n",
      "episode 59, reward -110.0, memory_length 2000, epsilon 0.9709211683324178 total_time 725.0\n",
      "episode 69, reward 159.0, memory_length 2000, epsilon 0.9660786788030947 total_time 723.0\n",
      "episode 79, reward -297.0, memory_length 2000, epsilon 0.9612603412910584 total_time 721.0\n",
      "episode 89, reward 202.0, memory_length 2000, epsilon 0.9564660353376199 total_time 727.0\n",
      "episode 99, reward -48.0, memory_length 2000, epsilon 0.9516956410848808 total_time 723.0\n",
      "episode 109, reward -165.0, memory_length 2000, epsilon 0.9469490392727365 total_time 724.0\n",
      "episode 119, reward -229.0, memory_length 2000, epsilon 0.9422261112358942 total_time 725.0\n",
      "episode 129, reward -351.0, memory_length 2000, epsilon 0.9375267389009072 total_time 723.0\n",
      "episode 139, reward -45.0, memory_length 2000, epsilon 0.9328508047832221 total_time 721.0\n",
      "episode 149, reward 177.0, memory_length 2000, epsilon 0.9281981919842428 total_time 723.0\n",
      "episode 159, reward -93.0, memory_length 2000, epsilon 0.9235687841884068 total_time 723.0\n",
      "episode 169, reward -115.0, memory_length 2000, epsilon 0.918962465660278 total_time 723.0\n",
      "episode 179, reward -183.0, memory_length 2000, epsilon 0.9143791212416534 total_time 722.0\n",
      "episode 189, reward -45.0, memory_length 2000, epsilon 0.9098186363486838 total_time 728.0\n",
      "episode 199, reward 4.0, memory_length 2000, epsilon 0.9052808969690094 total_time 721.0\n",
      "episode 209, reward -240.0, memory_length 2000, epsilon 0.9007657896589091 total_time 721.0\n",
      "episode 219, reward -188.0, memory_length 2000, epsilon 0.8962732015404654 total_time 723.0\n",
      "episode 229, reward -297.0, memory_length 2000, epsilon 0.891803020298741 total_time 728.0\n",
      "episode 239, reward 10.0, memory_length 2000, epsilon 0.8873551341789723 total_time 722.0\n",
      "episode 249, reward 239.0, memory_length 2000, epsilon 0.8829294319837746 total_time 722.0\n",
      "episode 259, reward -128.0, memory_length 2000, epsilon 0.8785258030703623 total_time 726.0\n",
      "episode 269, reward -233.0, memory_length 2000, epsilon 0.8741441373477834 total_time 723.0\n",
      "episode 279, reward 306.0, memory_length 2000, epsilon 0.8697843252741666 total_time 723.0\n",
      "episode 289, reward 50.0, memory_length 2000, epsilon 0.8654462578539829 total_time 723.0\n",
      "episode 299, reward -149.0, memory_length 2000, epsilon 0.8611298266353209 total_time 721.0\n",
      "episode 309, reward -89.0, memory_length 2000, epsilon 0.8568349237071754 total_time 721.0\n",
      "episode 319, reward 69.0, memory_length 2000, epsilon 0.8525614416967494 total_time 726.0\n",
      "episode 329, reward -203.0, memory_length 2000, epsilon 0.84830927376677 total_time 726.0\n",
      "episode 339, reward 23.0, memory_length 2000, epsilon 0.8440783136128177 total_time 735.0\n",
      "episode 349, reward -34.0, memory_length 2000, epsilon 0.8398684554606681 total_time 721.0\n",
      "episode 359, reward -4.0, memory_length 2000, epsilon 0.8356795940636483 total_time 723.0\n",
      "episode 369, reward -69.0, memory_length 2000, epsilon 0.8315116247000052 total_time 721.0\n",
      "episode 379, reward 227.0, memory_length 2000, epsilon 0.8273644431702872 total_time 730.0\n",
      "episode 389, reward 106.0, memory_length 2000, epsilon 0.8232379457947406 total_time 726.0\n",
      "episode 399, reward -242.0, memory_length 2000, epsilon 0.819132029410716 total_time 726.0\n",
      "episode 409, reward 163.0, memory_length 2000, epsilon 0.8150465913700896 total_time 723.0\n",
      "episode 419, reward 53.0, memory_length 2000, epsilon 0.8109815295366979 total_time 721.0\n",
      "episode 429, reward 46.0, memory_length 2000, epsilon 0.8069367422837833 total_time 722.0\n",
      "episode 439, reward 168.0, memory_length 2000, epsilon 0.8029121284914538 total_time 723.0\n",
      "episode 449, reward 110.0, memory_length 2000, epsilon 0.7989075875441549 total_time 722.0\n",
      "episode 459, reward 315.0, memory_length 2000, epsilon 0.7949230193281545 total_time 728.0\n",
      "episode 469, reward -75.0, memory_length 2000, epsilon 0.7909583242290396 total_time 725.0\n",
      "episode 479, reward 114.0, memory_length 2000, epsilon 0.7870134031292261 total_time 725.0\n",
      "episode 489, reward 122.0, memory_length 2000, epsilon 0.7830881574054811 total_time 723.0\n",
      "episode 499, reward 392.0, memory_length 2000, epsilon 0.7791824889264571 total_time 724.0\n",
      "episode 509, reward 411.0, memory_length 2000, epsilon 0.7752963000502389 total_time 722.0\n",
      "episode 519, reward 28.0, memory_length 2000, epsilon 0.7714294936219019 total_time 730.0\n",
      "episode 529, reward 91.0, memory_length 2000, epsilon 0.7675819729710842 total_time 729.0\n",
      "episode 539, reward 523.0, memory_length 2000, epsilon 0.763753641909569 total_time 723.0\n",
      "episode 549, reward -151.0, memory_length 2000, epsilon 0.7599444047288803 total_time 723.0\n",
      "episode 559, reward 414.0, memory_length 2000, epsilon 0.7561541661978903 total_time 726.0\n",
      "episode 569, reward 488.0, memory_length 2000, epsilon 0.7523828315604384 total_time 731.0\n",
      "episode 579, reward 276.0, memory_length 2000, epsilon 0.7486303065329623 total_time 729.0\n",
      "episode 589, reward 334.0, memory_length 2000, epsilon 0.7448964973021404 total_time 722.0\n",
      "episode 599, reward 264.0, memory_length 2000, epsilon 0.7411813105225479 total_time 725.0\n",
      "episode 609, reward 387.0, memory_length 2000, epsilon 0.7374846533143217 total_time 722.0\n",
      "episode 619, reward 623.0, memory_length 2000, epsilon 0.733806433260839 total_time 724.0\n",
      "episode 629, reward 471.0, memory_length 2000, epsilon 0.7301465584064071 total_time 721.0\n",
      "episode 639, reward 306.0, memory_length 2000, epsilon 0.7265049372539636 total_time 722.0\n",
      "episode 649, reward 88.0, memory_length 2000, epsilon 0.7228814787627905 total_time 723.0\n",
      "episode 659, reward 374.0, memory_length 2000, epsilon 0.7192760923462365 total_time 721.0\n",
      "episode 669, reward 330.0, memory_length 2000, epsilon 0.7156886878694535 total_time 722.0\n",
      "episode 679, reward 613.0, memory_length 2000, epsilon 0.7121191756471427 total_time 727.0\n",
      "episode 689, reward 384.0, memory_length 2000, epsilon 0.7085674664413126 total_time 723.0\n",
      "episode 699, reward 192.0, memory_length 2000, epsilon 0.7050334714590482 total_time 723.0\n",
      "episode 709, reward 145.0, memory_length 2000, epsilon 0.7015171023502909 total_time 729.0\n",
      "episode 719, reward 377.0, memory_length 2000, epsilon 0.6980182712056295 total_time 724.0\n",
      "episode 729, reward 399.0, memory_length 2000, epsilon 0.6945368905541035 total_time 722.0\n",
      "episode 739, reward 477.0, memory_length 2000, epsilon 0.6910728733610152 total_time 722.0\n",
      "episode 749, reward 210.0, memory_length 2000, epsilon 0.6876261330257543 total_time 726.0\n",
      "episode 759, reward 226.0, memory_length 2000, epsilon 0.684196583379633 total_time 723.0\n",
      "episode 769, reward 75.0, memory_length 2000, epsilon 0.6807841386837313 total_time 721.0\n",
      "episode 779, reward 507.0, memory_length 2000, epsilon 0.6773887136267543 total_time 725.0\n",
      "episode 789, reward 135.0, memory_length 2000, epsilon 0.6740102233228988 total_time 728.0\n",
      "episode 799, reward 275.0, memory_length 2000, epsilon 0.670648583309731 total_time 726.0\n",
      "episode 809, reward 510.0, memory_length 2000, epsilon 0.6673037095460755 total_time 723.0\n",
      "episode 819, reward 852.0, memory_length 2000, epsilon 0.6639755184099142 total_time 733.0\n",
      "episode 829, reward 664.0, memory_length 2000, epsilon 0.6606639266962953 total_time 724.0\n",
      "episode 839, reward 339.0, memory_length 2000, epsilon 0.6573688516152534 total_time 723.0\n",
      "episode 849, reward 171.0, memory_length 2000, epsilon 0.6540902107897397 total_time 725.0\n",
      "episode 859, reward -270.0, memory_length 2000, epsilon 0.6508279222535631 total_time 727.0\n",
      "episode 869, reward 186.0, memory_length 2000, epsilon 0.64758190444934 total_time 722.0\n",
      "episode 879, reward 608.0, memory_length 2000, epsilon 0.6443520762264566 total_time 727.0\n",
      "episode 889, reward 537.0, memory_length 2000, epsilon 0.6411383568390387 total_time 736.0\n",
      "episode 899, reward 524.0, memory_length 2000, epsilon 0.6379406659439346 total_time 730.0\n",
      "episode 909, reward 536.0, memory_length 2000, epsilon 0.6347589235987051 total_time 723.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 919, reward 579.0, memory_length 2000, epsilon 0.631593050259626 total_time 729.0\n",
      "episode 929, reward 596.0, memory_length 2000, epsilon 0.6284429667796988 total_time 724.0\n",
      "episode 939, reward 550.0, memory_length 2000, epsilon 0.6253085944066726 total_time 722.0\n",
      "episode 949, reward 544.0, memory_length 2000, epsilon 0.6221898547810748 total_time 731.0\n",
      "episode 959, reward 437.0, memory_length 2000, epsilon 0.6190866699342522 total_time 727.0\n",
      "episode 969, reward 640.0, memory_length 2000, epsilon 0.6159989622864221 total_time 725.0\n",
      "episode 979, reward 478.0, memory_length 2000, epsilon 0.6129266546447325 total_time 723.0\n",
      "episode 989, reward 330.0, memory_length 2000, epsilon 0.6098696702013323 total_time 722.0\n",
      "episode 999, reward 604.0, memory_length 2000, epsilon 0.6068279325314512 total_time 727.0\n",
      "Saving Model 1000\n",
      "episode 1009, reward 627.0, memory_length 2000, epsilon 0.6038013655914889 total_time 724.0\n",
      "episode 1019, reward 662.0, memory_length 2000, epsilon 0.6007898937171146 total_time 733.0\n",
      "episode 1029, reward 273.0, memory_length 2000, epsilon 0.5977934416213744 total_time 722.0\n",
      "episode 1039, reward 575.0, memory_length 2000, epsilon 0.5948119343928097 total_time 725.0\n",
      "episode 1049, reward 475.0, memory_length 2000, epsilon 0.5918452974935846 total_time 721.0\n",
      "episode 1059, reward 753.0, memory_length 2000, epsilon 0.5888934567576223 total_time 724.0\n",
      "episode 1069, reward 303.0, memory_length 2000, epsilon 0.5859563383887504 total_time 736.0\n",
      "episode 1079, reward 329.0, memory_length 2000, epsilon 0.5830338689588568 total_time 727.0\n",
      "episode 1089, reward 321.0, memory_length 2000, epsilon 0.5801259754060536 total_time 727.0\n",
      "episode 1099, reward 644.0, memory_length 2000, epsilon 0.5772325850328504 total_time 721.0\n",
      "episode 1109, reward 629.0, memory_length 2000, epsilon 0.5743536255043372 total_time 725.0\n",
      "episode 1119, reward 972.0, memory_length 2000, epsilon 0.5714890248463761 total_time 727.0\n",
      "episode 1129, reward 358.0, memory_length 2000, epsilon 0.5686387114438011 total_time 721.0\n",
      "episode 1139, reward 348.0, memory_length 2000, epsilon 0.5658026140386287 total_time 721.0\n",
      "episode 1149, reward 824.0, memory_length 2000, epsilon 0.5629806617282764 total_time 729.0\n",
      "episode 1159, reward 155.0, memory_length 2000, epsilon 0.5601727839637891 total_time 725.0\n",
      "episode 1169, reward 875.0, memory_length 2000, epsilon 0.5573789105480766 total_time 724.0\n",
      "episode 1179, reward 606.0, memory_length 2000, epsilon 0.5545989716341581 total_time 726.0\n",
      "episode 1189, reward 264.0, memory_length 2000, epsilon 0.5518328977234156 total_time 722.0\n",
      "episode 1199, reward 673.0, memory_length 2000, epsilon 0.5490806196638577 total_time 724.0\n",
      "episode 1209, reward 467.0, memory_length 2000, epsilon 0.5463420686483893 total_time 723.0\n",
      "episode 1219, reward 486.0, memory_length 2000, epsilon 0.5436171762130925 total_time 722.0\n",
      "episode 1229, reward 479.0, memory_length 2000, epsilon 0.5409058742355145 total_time 726.0\n",
      "episode 1239, reward 388.0, memory_length 2000, epsilon 0.5382080949329644 total_time 722.0\n",
      "episode 1249, reward 545.0, memory_length 2000, epsilon 0.5355237708608195 total_time 727.0\n",
      "episode 1259, reward 527.0, memory_length 2000, epsilon 0.5328528349108379 total_time 727.0\n",
      "episode 1269, reward 239.0, memory_length 2000, epsilon 0.5301952203094819 total_time 722.0\n",
      "episode 1279, reward 392.0, memory_length 2000, epsilon 0.5275508606162479 total_time 727.0\n",
      "episode 1289, reward 568.0, memory_length 2000, epsilon 0.5249196897220061 total_time 723.0\n",
      "episode 1299, reward 667.0, memory_length 2000, epsilon 0.5223016418473468 total_time 724.0\n",
      "episode 1309, reward 248.0, memory_length 2000, epsilon 0.519696651540937 total_time 731.0\n",
      "episode 1319, reward 467.0, memory_length 2000, epsilon 0.5171046536778833 total_time 724.0\n",
      "episode 1329, reward 240.0, memory_length 2000, epsilon 0.514525583458104 total_time 725.0\n",
      "episode 1339, reward 769.0, memory_length 2000, epsilon 0.5119593764047093 total_time 723.0\n",
      "episode 1349, reward 560.0, memory_length 2000, epsilon 0.5094059683623896 total_time 724.0\n",
      "episode 1359, reward 697.0, memory_length 2000, epsilon 0.5068652954958104 total_time 728.0\n",
      "episode 1369, reward 833.0, memory_length 2000, epsilon 0.5043372942880178 total_time 723.0\n",
      "episode 1379, reward 246.0, memory_length 2000, epsilon 0.50182190153885 total_time 721.0\n",
      "episode 1389, reward 538.0, memory_length 2000, epsilon 0.49931905436335716 total_time 723.0\n",
      "episode 1399, reward 924.0, memory_length 2000, epsilon 0.49682869019022974 total_time 725.0\n",
      "episode 1409, reward 757.0, memory_length 2000, epsilon 0.49435074676023355 total_time 728.0\n",
      "episode 1419, reward 968.0, memory_length 2000, epsilon 0.4918851621246539 total_time 724.0\n",
      "episode 1429, reward 412.0, memory_length 2000, epsilon 0.4894318746437464 total_time 721.0\n",
      "episode 1439, reward 889.0, memory_length 2000, epsilon 0.4869908229851962 total_time 723.0\n",
      "episode 1449, reward 729.0, memory_length 2000, epsilon 0.48456194612258474 total_time 721.0\n",
      "episode 1459, reward 456.0, memory_length 2000, epsilon 0.48214518333386397 total_time 726.0\n",
      "episode 1469, reward 834.0, memory_length 2000, epsilon 0.47974047419983834 total_time 728.0\n",
      "episode 1479, reward 623.0, memory_length 2000, epsilon 0.4773477586026542 total_time 726.0\n",
      "episode 1489, reward 629.0, memory_length 2000, epsilon 0.474966976724297 total_time 722.0\n",
      "episode 1499, reward 963.0, memory_length 2000, epsilon 0.47259806904509577 total_time 728.0\n",
      "episode 1509, reward 725.0, memory_length 2000, epsilon 0.4702409763422352 total_time 723.0\n",
      "episode 1519, reward 622.0, memory_length 2000, epsilon 0.4678956396882749 total_time 723.0\n",
      "episode 1529, reward 819.0, memory_length 2000, epsilon 0.4655620004496764 total_time 728.0\n",
      "episode 1539, reward 1042.0, memory_length 2000, epsilon 0.46324000028533724 total_time 723.0\n",
      "episode 1549, reward 567.0, memory_length 2000, epsilon 0.4609295811451323 total_time 721.0\n",
      "episode 1559, reward 644.0, memory_length 2000, epsilon 0.4586306852684627 total_time 729.0\n",
      "episode 1569, reward 840.0, memory_length 2000, epsilon 0.4563432551828119 total_time 723.0\n",
      "episode 1579, reward 808.0, memory_length 2000, epsilon 0.4540672337023085 total_time 722.0\n",
      "episode 1589, reward 721.0, memory_length 2000, epsilon 0.45180256392629703 total_time 727.0\n",
      "episode 1599, reward 722.0, memory_length 2000, epsilon 0.4495491892379152 total_time 723.0\n",
      "episode 1609, reward 600.0, memory_length 2000, epsilon 0.4473070533026783 total_time 723.0\n",
      "episode 1619, reward 917.0, memory_length 2000, epsilon 0.4450761000670712 total_time 723.0\n",
      "episode 1629, reward 680.0, memory_length 2000, epsilon 0.4428562737571469 total_time 722.0\n",
      "episode 1639, reward 785.0, memory_length 2000, epsilon 0.44064751887713194 total_time 727.0\n",
      "episode 1649, reward 882.0, memory_length 2000, epsilon 0.4384497802080393 total_time 730.0\n",
      "episode 1659, reward 626.0, memory_length 2000, epsilon 0.4362630028062879 total_time 728.0\n",
      "episode 1669, reward 504.0, memory_length 2000, epsilon 0.43408713200232857 total_time 726.0\n",
      "episode 1679, reward 1016.0, memory_length 2000, epsilon 0.43192211339927816 total_time 722.0\n",
      "episode 1689, reward 588.0, memory_length 2000, epsilon 0.4297678928715586 total_time 721.0\n",
      "episode 1699, reward 654.0, memory_length 2000, epsilon 0.4276244165635446 total_time 727.0\n",
      "episode 1709, reward 631.0, memory_length 2000, epsilon 0.42549163088821684 total_time 726.0\n",
      "episode 1719, reward 792.0, memory_length 2000, epsilon 0.4233694825258223 total_time 725.0\n",
      "episode 1729, reward 646.0, memory_length 2000, epsilon 0.4212579184225415 total_time 722.0\n",
      "episode 1739, reward 1134.0, memory_length 2000, epsilon 0.4191568857891617 total_time 722.0\n",
      "episode 1749, reward 329.0, memory_length 2000, epsilon 0.4170663320997578 total_time 722.0\n",
      "episode 1759, reward 973.0, memory_length 2000, epsilon 0.4149862050903786 total_time 725.0\n",
      "episode 1769, reward 729.0, memory_length 2000, epsilon 0.4129164527577405 total_time 721.0\n",
      "episode 1779, reward 950.0, memory_length 2000, epsilon 0.41085702335792745 total_time 722.0\n",
      "episode 1789, reward 880.0, memory_length 2000, epsilon 0.40880786540509717 total_time 721.0\n",
      "episode 1799, reward 851.0, memory_length 2000, epsilon 0.4067689276701942 total_time 731.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1809, reward 992.0, memory_length 2000, epsilon 0.40474015917966877 total_time 726.0\n",
      "episode 1819, reward 924.0, memory_length 2000, epsilon 0.4027215092142031 total_time 729.0\n",
      "episode 1829, reward 955.0, memory_length 2000, epsilon 0.4007129273074429 total_time 729.0\n",
      "episode 1839, reward 1132.0, memory_length 2000, epsilon 0.39871436324473586 total_time 722.0\n",
      "episode 1849, reward 283.0, memory_length 2000, epsilon 0.3967257670618763 total_time 721.0\n",
      "episode 1859, reward 617.0, memory_length 2000, epsilon 0.3947470890438561 total_time 726.0\n",
      "episode 1869, reward 736.0, memory_length 2000, epsilon 0.3927782797236218 total_time 723.0\n",
      "episode 1879, reward 1041.0, memory_length 2000, epsilon 0.3908192898808378 total_time 721.0\n",
      "episode 1889, reward 932.0, memory_length 2000, epsilon 0.388870070540656 total_time 727.0\n",
      "episode 1899, reward 668.0, memory_length 2000, epsilon 0.38693057297249134 total_time 727.0\n",
      "episode 1909, reward 1059.0, memory_length 2000, epsilon 0.3850007486888037 total_time 725.0\n",
      "episode 1919, reward 888.0, memory_length 2000, epsilon 0.3830805494438854 total_time 724.0\n",
      "episode 1929, reward 1044.0, memory_length 2000, epsilon 0.38116992723265536 total_time 723.0\n",
      "episode 1939, reward 1292.0, memory_length 2000, epsilon 0.3792688342894587 total_time 725.0\n",
      "episode 1949, reward 640.0, memory_length 2000, epsilon 0.3773772230868729 total_time 722.0\n",
      "episode 1959, reward 1350.0, memory_length 2000, epsilon 0.37549504633451936 total_time 721.0\n",
      "episode 1969, reward 713.0, memory_length 2000, epsilon 0.37362225697788115 total_time 725.0\n",
      "episode 1979, reward 883.0, memory_length 2000, epsilon 0.37175880819712703 total_time 727.0\n",
      "episode 1989, reward 720.0, memory_length 2000, epsilon 0.3699046534059402 total_time 728.0\n",
      "episode 1999, reward 564.0, memory_length 2000, epsilon 0.3680597462503545 total_time 723.0\n",
      "Saving Model 2000\n",
      "episode 2009, reward 932.0, memory_length 2000, epsilon 0.3662240406075948 total_time 723.0\n",
      "episode 2019, reward 600.0, memory_length 2000, epsilon 0.3643974905849244 total_time 730.0\n",
      "episode 2029, reward 779.0, memory_length 2000, epsilon 0.3625800505184978 total_time 728.0\n",
      "episode 2039, reward 618.0, memory_length 2000, epsilon 0.3607716749722184 total_time 725.0\n",
      "episode 2049, reward 1008.0, memory_length 2000, epsilon 0.3589723187366037 total_time 726.0\n",
      "episode 2059, reward 1223.0, memory_length 2000, epsilon 0.35718193682765376 total_time 724.0\n",
      "episode 2069, reward 756.0, memory_length 2000, epsilon 0.3554004844857278 total_time 722.0\n",
      "episode 2079, reward 902.0, memory_length 2000, epsilon 0.35362791717442443 total_time 727.0\n",
      "episode 2089, reward 545.0, memory_length 2000, epsilon 0.35186419057946866 total_time 723.0\n",
      "episode 2099, reward 636.0, memory_length 2000, epsilon 0.3501092606076035 total_time 726.0\n",
      "episode 2109, reward 750.0, memory_length 2000, epsilon 0.3483630833854885 total_time 723.0\n",
      "episode 2119, reward 1107.0, memory_length 2000, epsilon 0.34662561525860197 total_time 731.0\n",
      "episode 2129, reward 797.0, memory_length 2000, epsilon 0.34489681279015044 total_time 722.0\n",
      "episode 2139, reward 775.0, memory_length 2000, epsilon 0.34317663275998195 total_time 727.0\n",
      "episode 2149, reward 731.0, memory_length 2000, epsilon 0.3414650321635064 total_time 725.0\n",
      "episode 2159, reward -7.0, memory_length 2000, epsilon 0.33976196821061944 total_time 721.0\n",
      "episode 2169, reward 1027.0, memory_length 2000, epsilon 0.3380673983246338 total_time 724.0\n",
      "episode 2179, reward 941.0, memory_length 2000, epsilon 0.336381280141214 total_time 725.0\n",
      "episode 2189, reward 1137.0, memory_length 2000, epsilon 0.33470357150731744 total_time 723.0\n",
      "episode 2199, reward 738.0, memory_length 2000, epsilon 0.3330342304801412 total_time 724.0\n",
      "episode 2209, reward 1004.0, memory_length 2000, epsilon 0.33137321532607245 total_time 729.0\n",
      "episode 2219, reward 713.0, memory_length 2000, epsilon 0.3297204845196459 total_time 724.0\n",
      "episode 2229, reward 983.0, memory_length 2000, epsilon 0.32807599674250526 total_time 723.0\n",
      "episode 2239, reward 1089.0, memory_length 2000, epsilon 0.32643971088237056 total_time 731.0\n",
      "episode 2249, reward 1269.0, memory_length 2000, epsilon 0.32481158603200994 total_time 735.0\n",
      "episode 2259, reward 986.0, memory_length 2000, epsilon 0.32319158148821747 total_time 721.0\n",
      "episode 2269, reward 1271.0, memory_length 2000, epsilon 0.3215796567507951 total_time 721.0\n",
      "episode 2279, reward 1189.0, memory_length 2000, epsilon 0.31997577152154044 total_time 724.0\n",
      "episode 2289, reward 793.0, memory_length 2000, epsilon 0.31837988570323916 total_time 724.0\n",
      "episode 2299, reward 861.0, memory_length 2000, epsilon 0.3167919593986629 total_time 723.0\n",
      "episode 2309, reward 1236.0, memory_length 2000, epsilon 0.3152119529095711 total_time 721.0\n",
      "episode 2319, reward 999.0, memory_length 2000, epsilon 0.3136398267357194 total_time 721.0\n",
      "episode 2329, reward 824.0, memory_length 2000, epsilon 0.31207554157387146 total_time 725.0\n",
      "episode 2339, reward 1044.0, memory_length 2000, epsilon 0.3105190583168168 total_time 722.0\n",
      "episode 2349, reward 1005.0, memory_length 2000, epsilon 0.30897033805239293 total_time 726.0\n",
      "episode 2359, reward 801.0, memory_length 2000, epsilon 0.3074293420625127 total_time 727.0\n",
      "episode 2369, reward 1242.0, memory_length 2000, epsilon 0.3058960318221959 total_time 731.0\n",
      "episode 2379, reward 1173.0, memory_length 2000, epsilon 0.30437036899860687 total_time 722.0\n",
      "episode 2389, reward 950.0, memory_length 2000, epsilon 0.3028523154500953 total_time 734.0\n",
      "episode 2399, reward 905.0, memory_length 2000, epsilon 0.30134183322524366 total_time 721.0\n",
      "episode 2409, reward 837.0, memory_length 2000, epsilon 0.29983888456191743 total_time 722.0\n",
      "episode 2419, reward 1105.0, memory_length 2000, epsilon 0.29834343188632195 total_time 721.0\n",
      "episode 2429, reward 1220.0, memory_length 2000, epsilon 0.2968554378120623 total_time 732.0\n",
      "episode 2439, reward 975.0, memory_length 2000, epsilon 0.2953748651392093 total_time 727.0\n",
      "episode 2449, reward 564.0, memory_length 2000, epsilon 0.2939016768533689 total_time 723.0\n",
      "episode 2459, reward 864.0, memory_length 2000, epsilon 0.2924358361247571 total_time 725.0\n",
      "episode 2469, reward 1002.0, memory_length 2000, epsilon 0.2909773063072796 total_time 725.0\n",
      "episode 2479, reward 1350.0, memory_length 2000, epsilon 0.28952605093761474 total_time 739.0\n",
      "episode 2489, reward 983.0, memory_length 2000, epsilon 0.28808203373430286 total_time 727.0\n",
      "episode 2499, reward 1290.0, memory_length 2000, epsilon 0.28664521859683867 total_time 722.0\n",
      "episode 2509, reward 878.0, memory_length 2000, epsilon 0.2852155696047688 total_time 721.0\n",
      "episode 2519, reward 878.0, memory_length 2000, epsilon 0.28379305101679403 total_time 723.0\n",
      "episode 2529, reward 969.0, memory_length 2000, epsilon 0.28237762726987564 total_time 730.0\n",
      "episode 2539, reward 1107.0, memory_length 2000, epsilon 0.28096926297834607 total_time 722.0\n",
      "episode 2549, reward 784.0, memory_length 2000, epsilon 0.2795679229330249 total_time 727.0\n",
      "episode 2559, reward 927.0, memory_length 2000, epsilon 0.27817357210033783 total_time 721.0\n",
      "episode 2569, reward 1301.0, memory_length 2000, epsilon 0.27678617562144153 total_time 722.0\n",
      "episode 2579, reward 1076.0, memory_length 2000, epsilon 0.2754056988113517 total_time 726.0\n",
      "episode 2589, reward 1095.0, memory_length 2000, epsilon 0.27403210715807624 total_time 723.0\n",
      "episode 2599, reward 720.0, memory_length 2000, epsilon 0.2726653663217522 total_time 721.0\n",
      "episode 2609, reward 1616.0, memory_length 2000, epsilon 0.27130544213378754 total_time 725.0\n",
      "episode 2619, reward 831.0, memory_length 2000, epsilon 0.2699523005960067 total_time 722.0\n",
      "episode 2629, reward 701.0, memory_length 2000, epsilon 0.26860590787980093 total_time 722.0\n",
      "episode 2639, reward 1366.0, memory_length 2000, epsilon 0.26726623032528185 total_time 721.0\n",
      "episode 2649, reward 1178.0, memory_length 2000, epsilon 0.2659332344404412 total_time 722.0\n",
      "episode 2659, reward 1008.0, memory_length 2000, epsilon 0.2646068869003122 total_time 730.0\n",
      "episode 2669, reward 1044.0, memory_length 2000, epsilon 0.2632871545461373 total_time 728.0\n",
      "episode 2679, reward 981.0, memory_length 2000, epsilon 0.261974004384539 total_time 725.0\n",
      "episode 2689, reward 1223.0, memory_length 2000, epsilon 0.26066740358669477 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2699, reward 1417.0, memory_length 2000, epsilon 0.25936731948751673 total_time 723.0\n",
      "episode 2709, reward 1364.0, memory_length 2000, epsilon 0.2580737195848345 total_time 723.0\n",
      "episode 2719, reward 1062.0, memory_length 2000, epsilon 0.25678657153858325 total_time 723.0\n",
      "episode 2729, reward 1634.0, memory_length 2000, epsilon 0.2555058431699948 total_time 721.0\n",
      "episode 2739, reward 994.0, memory_length 2000, epsilon 0.25423150246079323 total_time 723.0\n",
      "episode 2749, reward 1003.0, memory_length 2000, epsilon 0.2529635175523944 total_time 721.0\n",
      "episode 2759, reward 1524.0, memory_length 2000, epsilon 0.25170185674510953 total_time 722.0\n",
      "episode 2769, reward 1306.0, memory_length 2000, epsilon 0.25044648849735274 total_time 724.0\n",
      "episode 2779, reward 1133.0, memory_length 2000, epsilon 0.2491973814248526 total_time 727.0\n",
      "episode 2789, reward 874.0, memory_length 2000, epsilon 0.24795450429986704 total_time 722.0\n",
      "episode 2799, reward 1003.0, memory_length 2000, epsilon 0.24671782605040335 total_time 725.0\n",
      "episode 2809, reward 1166.0, memory_length 2000, epsilon 0.24548731575944074 total_time 728.0\n",
      "episode 2819, reward 1253.0, memory_length 2000, epsilon 0.244262942664158 total_time 727.0\n",
      "episode 2829, reward 1300.0, memory_length 2000, epsilon 0.24304467615516384 total_time 723.0\n",
      "episode 2839, reward 1261.0, memory_length 2000, epsilon 0.24183248577573216 total_time 723.0\n",
      "episode 2849, reward 866.0, memory_length 2000, epsilon 0.24062634122104032 total_time 724.0\n",
      "episode 2859, reward 1527.0, memory_length 2000, epsilon 0.2394262123374117 total_time 736.0\n",
      "episode 2869, reward 1025.0, memory_length 2000, epsilon 0.23823206912156156 total_time 722.0\n",
      "episode 2879, reward 1104.0, memory_length 2000, epsilon 0.23704388171984747 total_time 731.0\n",
      "episode 2889, reward 1014.0, memory_length 2000, epsilon 0.23586162042752232 total_time 726.0\n",
      "episode 2899, reward 1290.0, memory_length 2000, epsilon 0.23468525568799242 total_time 722.0\n",
      "episode 2909, reward 1332.0, memory_length 2000, epsilon 0.23351475809207786 total_time 726.0\n",
      "episode 2919, reward 1139.0, memory_length 2000, epsilon 0.2323500983772779 total_time 725.0\n",
      "episode 2929, reward 573.0, memory_length 2000, epsilon 0.2311912474270389 total_time 721.0\n",
      "episode 2939, reward 927.0, memory_length 2000, epsilon 0.23003817627002682 total_time 734.0\n",
      "episode 2949, reward 1229.0, memory_length 2000, epsilon 0.22889085607940265 total_time 728.0\n",
      "episode 2959, reward 1251.0, memory_length 2000, epsilon 0.22774925817210187 total_time 728.0\n",
      "episode 2969, reward 1028.0, memory_length 2000, epsilon 0.22661335400811736 total_time 726.0\n",
      "episode 2979, reward 1207.0, memory_length 2000, epsilon 0.2254831151897858 total_time 725.0\n",
      "episode 2989, reward 902.0, memory_length 2000, epsilon 0.22435851346107796 total_time 721.0\n",
      "episode 2999, reward 695.0, memory_length 2000, epsilon 0.22323952070689196 total_time 722.0\n",
      "Saving Model 3000\n",
      "episode 3009, reward 1243.0, memory_length 2000, epsilon 0.22212610895235071 total_time 727.0\n",
      "episode 3019, reward 1027.0, memory_length 2000, epsilon 0.22101825036210232 total_time 726.0\n",
      "episode 3029, reward 1416.0, memory_length 2000, epsilon 0.21991591723962442 total_time 722.0\n",
      "episode 3039, reward 1438.0, memory_length 2000, epsilon 0.21881908202653141 total_time 724.0\n",
      "episode 3049, reward 730.0, memory_length 2000, epsilon 0.21772771730188595 total_time 724.0\n",
      "episode 3059, reward 1600.0, memory_length 2000, epsilon 0.216641795781513 total_time 722.0\n",
      "episode 3069, reward 1446.0, memory_length 2000, epsilon 0.21556129031731802 total_time 724.0\n",
      "episode 3079, reward 1181.0, memory_length 2000, epsilon 0.21448617389660815 total_time 722.0\n",
      "episode 3089, reward 903.0, memory_length 2000, epsilon 0.21341641964141686 total_time 730.0\n",
      "episode 3099, reward 1338.0, memory_length 2000, epsilon 0.21235200080783204 total_time 723.0\n",
      "episode 3109, reward 1402.0, memory_length 2000, epsilon 0.21129289078532745 total_time 721.0\n",
      "episode 3119, reward 1251.0, memory_length 2000, epsilon 0.2102390630960973 total_time 721.0\n",
      "episode 3129, reward 630.0, memory_length 2000, epsilon 0.20919049139439458 total_time 728.0\n",
      "episode 3139, reward 1219.0, memory_length 2000, epsilon 0.20814714946587198 total_time 722.0\n",
      "episode 3149, reward 1271.0, memory_length 2000, epsilon 0.2071090112269271 total_time 723.0\n",
      "episode 3159, reward 1530.0, memory_length 2000, epsilon 0.2060760507240498 total_time 726.0\n",
      "episode 3169, reward 1414.0, memory_length 2000, epsilon 0.20504824213317377 total_time 724.0\n",
      "episode 3179, reward 738.0, memory_length 2000, epsilon 0.2040255597590306 total_time 724.0\n",
      "episode 3189, reward 1160.0, memory_length 2000, epsilon 0.20300797803450785 total_time 721.0\n",
      "episode 3199, reward 1230.0, memory_length 2000, epsilon 0.2019954715200092 total_time 721.0\n",
      "episode 3209, reward 1395.0, memory_length 2000, epsilon 0.20098801490281926 total_time 721.0\n",
      "episode 3219, reward 1209.0, memory_length 2000, epsilon 0.19998558299646998 total_time 725.0\n",
      "episode 3229, reward 1026.0, memory_length 2000, epsilon 0.1989881507401115 total_time 726.0\n",
      "episode 3239, reward 1137.0, memory_length 2000, epsilon 0.19799569319788554 total_time 721.0\n",
      "episode 3249, reward 1313.0, memory_length 2000, epsilon 0.1970081855583018 total_time 722.0\n",
      "episode 3259, reward 1464.0, memory_length 2000, epsilon 0.19602560313361786 total_time 729.0\n",
      "episode 3269, reward 1580.0, memory_length 2000, epsilon 0.19504792135922194 total_time 727.0\n",
      "episode 3279, reward 1323.0, memory_length 2000, epsilon 0.19407511579301878 total_time 732.0\n",
      "episode 3289, reward 1455.0, memory_length 2000, epsilon 0.1931071621148185 total_time 724.0\n",
      "episode 3299, reward 1505.0, memory_length 2000, epsilon 0.19214403612572878 total_time 725.0\n",
      "episode 3309, reward 1134.0, memory_length 2000, epsilon 0.19118571374754967 total_time 733.0\n",
      "episode 3319, reward 1674.0, memory_length 2000, epsilon 0.1902321710221719 total_time 723.0\n",
      "episode 3329, reward 720.0, memory_length 2000, epsilon 0.1892833841109776 total_time 725.0\n",
      "episode 3339, reward 1415.0, memory_length 2000, epsilon 0.1883393292942446 total_time 723.0\n",
      "episode 3349, reward 612.0, memory_length 2000, epsilon 0.18739998297055327 total_time 722.0\n",
      "episode 3359, reward 1149.0, memory_length 2000, epsilon 0.18646532165619667 total_time 727.0\n",
      "episode 3369, reward 1269.0, memory_length 2000, epsilon 0.1855353219845932 total_time 721.0\n",
      "episode 3379, reward 1413.0, memory_length 2000, epsilon 0.18460996070570268 total_time 728.0\n",
      "episode 3389, reward 1542.0, memory_length 2000, epsilon 0.18368921468544486 total_time 723.0\n",
      "episode 3399, reward 1719.0, memory_length 2000, epsilon 0.18277306090512138 total_time 732.0\n",
      "episode 3409, reward 1359.0, memory_length 2000, epsilon 0.18186147646083992 total_time 729.0\n",
      "episode 3419, reward 1427.0, memory_length 2000, epsilon 0.18095443856294197 total_time 724.0\n",
      "episode 3429, reward 772.0, memory_length 2000, epsilon 0.1800519245354328 total_time 723.0\n",
      "episode 3439, reward 1605.0, memory_length 2000, epsilon 0.17915391181541473 total_time 723.0\n",
      "episode 3449, reward 1315.0, memory_length 2000, epsilon 0.17826037795252297 total_time 724.0\n",
      "episode 3459, reward 1508.0, memory_length 2000, epsilon 0.17737130060836448 total_time 730.0\n",
      "episode 3469, reward 1365.0, memory_length 2000, epsilon 0.17648665755595927 total_time 725.0\n",
      "episode 3479, reward 1320.0, memory_length 2000, epsilon 0.17560642667918497 total_time 729.0\n",
      "episode 3489, reward 1450.0, memory_length 2000, epsilon 0.17473058597222385 total_time 724.0\n",
      "episode 3499, reward 1346.0, memory_length 2000, epsilon 0.17385911353901257 total_time 727.0\n",
      "episode 3509, reward 1422.0, memory_length 2000, epsilon 0.17299198759269493 total_time 721.0\n",
      "episode 3519, reward 1161.0, memory_length 2000, epsilon 0.1721291864550771 total_time 728.0\n",
      "episode 3529, reward 1564.0, memory_length 2000, epsilon 0.17127068855608577 total_time 725.0\n",
      "episode 3539, reward 1300.0, memory_length 2000, epsilon 0.17041647243322863 total_time 722.0\n",
      "episode 3549, reward 1234.0, memory_length 2000, epsilon 0.16956651673105824 total_time 724.0\n",
      "episode 3559, reward 1225.0, memory_length 2000, epsilon 0.16872080020063768 total_time 722.0\n",
      "episode 3569, reward 1269.0, memory_length 2000, epsilon 0.16787930169900972 total_time 724.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3579, reward 1131.0, memory_length 2000, epsilon 0.16704200018866794 total_time 725.0\n",
      "episode 3589, reward 1214.0, memory_length 2000, epsilon 0.166208874737031 total_time 723.0\n",
      "episode 3599, reward 852.0, memory_length 2000, epsilon 0.1653799045159192 total_time 723.0\n",
      "episode 3609, reward 1422.0, memory_length 2000, epsilon 0.16455506880103385 total_time 727.0\n",
      "episode 3619, reward 1125.0, memory_length 2000, epsilon 0.1637343469714391 total_time 723.0\n",
      "episode 3629, reward 1231.0, memory_length 2000, epsilon 0.1629177185090465 total_time 724.0\n",
      "episode 3639, reward 973.0, memory_length 2000, epsilon 0.16210516299810185 total_time 722.0\n",
      "episode 3649, reward 1616.0, memory_length 2000, epsilon 0.16129666012467522 total_time 727.0\n",
      "episode 3659, reward 1671.0, memory_length 2000, epsilon 0.16049218967615253 total_time 723.0\n",
      "episode 3669, reward 1058.0, memory_length 2000, epsilon 0.15969173154073077 total_time 721.0\n",
      "episode 3679, reward 1851.0, memory_length 2000, epsilon 0.15889526570691476 total_time 728.0\n",
      "episode 3689, reward 1580.0, memory_length 2000, epsilon 0.15810277226301725 total_time 721.0\n",
      "episode 3699, reward 1203.0, memory_length 2000, epsilon 0.15731423139666081 total_time 722.0\n",
      "episode 3709, reward 1671.0, memory_length 2000, epsilon 0.15652962339428284 total_time 723.0\n",
      "episode 3719, reward 1542.0, memory_length 2000, epsilon 0.15574892864064224 total_time 722.0\n",
      "episode 3729, reward 1220.0, memory_length 2000, epsilon 0.1549721276183296 total_time 729.0\n",
      "episode 3739, reward 1512.0, memory_length 2000, epsilon 0.1541992009072789 total_time 722.0\n",
      "episode 3749, reward 1242.0, memory_length 2000, epsilon 0.1534301291842821 total_time 728.0\n",
      "episode 3759, reward 784.0, memory_length 2000, epsilon 0.15266489322250604 total_time 728.0\n",
      "episode 3769, reward 1583.0, memory_length 2000, epsilon 0.15190347389101183 total_time 722.0\n",
      "episode 3779, reward 1697.0, memory_length 2000, epsilon 0.1511458521542766 total_time 722.0\n",
      "episode 3789, reward 1402.0, memory_length 2000, epsilon 0.15039200907171735 total_time 725.0\n",
      "episode 3799, reward 1747.0, memory_length 2000, epsilon 0.14964192579721786 total_time 726.0\n",
      "episode 3809, reward 1459.0, memory_length 2000, epsilon 0.14889558357865715 total_time 728.0\n",
      "episode 3819, reward 1280.0, memory_length 2000, epsilon 0.1481529637574409 total_time 724.0\n",
      "episode 3829, reward 1247.0, memory_length 2000, epsilon 0.14741404776803485 total_time 732.0\n",
      "episode 3839, reward 1212.0, memory_length 2000, epsilon 0.1466788171375009 total_time 723.0\n",
      "episode 3849, reward 1400.0, memory_length 2000, epsilon 0.14594725348503484 total_time 724.0\n",
      "episode 3859, reward 1113.0, memory_length 2000, epsilon 0.14521933852150737 total_time 724.0\n",
      "episode 3869, reward 1770.0, memory_length 2000, epsilon 0.14449505404900642 total_time 729.0\n",
      "episode 3879, reward 1270.0, memory_length 2000, epsilon 0.1437743819603825 total_time 728.0\n",
      "episode 3889, reward 1335.0, memory_length 2000, epsilon 0.14305730423879587 total_time 726.0\n",
      "episode 3899, reward 1351.0, memory_length 2000, epsilon 0.1423438029572661 total_time 727.0\n",
      "episode 3909, reward 1542.0, memory_length 2000, epsilon 0.141633860278224 total_time 722.0\n",
      "episode 3919, reward 1504.0, memory_length 2000, epsilon 0.14092745845306562 total_time 727.0\n",
      "episode 3929, reward 1198.0, memory_length 2000, epsilon 0.14022457982170855 total_time 726.0\n",
      "episode 3939, reward 1314.0, memory_length 2000, epsilon 0.13952520681215042 total_time 726.0\n",
      "episode 3949, reward 1546.0, memory_length 2000, epsilon 0.1388293219400295 total_time 727.0\n",
      "episode 3959, reward 1347.0, memory_length 2000, epsilon 0.1381369078081878 total_time 731.0\n",
      "episode 3969, reward 1404.0, memory_length 2000, epsilon 0.13744794710623595 total_time 724.0\n",
      "episode 3979, reward 1575.0, memory_length 2000, epsilon 0.13676242261012048 total_time 721.0\n",
      "episode 3989, reward 1884.0, memory_length 2000, epsilon 0.13608031718169336 total_time 721.0\n",
      "episode 3999, reward 1833.0, memory_length 2000, epsilon 0.13540161376828327 total_time 721.0\n",
      "Saving Model 4000\n",
      "episode 4009, reward 1122.0, memory_length 2000, epsilon 0.13472629540226955 total_time 722.0\n",
      "episode 4019, reward 1469.0, memory_length 2000, epsilon 0.1340543452006579 total_time 721.0\n",
      "episode 4029, reward 1538.0, memory_length 2000, epsilon 0.1333857463646583 total_time 723.0\n",
      "episode 4039, reward 1649.0, memory_length 2000, epsilon 0.132720482179265 total_time 726.0\n",
      "episode 4049, reward 1143.0, memory_length 2000, epsilon 0.1320585360128386 total_time 734.0\n",
      "episode 4059, reward 1082.0, memory_length 2000, epsilon 0.1313998913166907 total_time 722.0\n",
      "episode 4069, reward 1138.0, memory_length 2000, epsilon 0.1307445316246694 total_time 723.0\n",
      "episode 4079, reward 1653.0, memory_length 2000, epsilon 0.13009244055274838 total_time 725.0\n",
      "episode 4089, reward 1499.0, memory_length 2000, epsilon 0.12944360179861678 total_time 725.0\n",
      "episode 4099, reward 1205.0, memory_length 2000, epsilon 0.12879799914127205 total_time 721.0\n",
      "episode 4109, reward 1084.0, memory_length 2000, epsilon 0.12815561644061407 total_time 724.0\n",
      "episode 4119, reward 1869.0, memory_length 2000, epsilon 0.1275164376370419 total_time 726.0\n",
      "episode 4129, reward 1799.0, memory_length 2000, epsilon 0.1268804467510521 total_time 725.0\n",
      "episode 4139, reward 1121.0, memory_length 2000, epsilon 0.12624762788283944 total_time 721.0\n",
      "episode 4149, reward 1632.0, memory_length 2000, epsilon 0.1256179652118993 total_time 722.0\n",
      "episode 4159, reward 1787.0, memory_length 2000, epsilon 0.12499144299663205 total_time 727.0\n",
      "episode 4169, reward 1320.0, memory_length 2000, epsilon 0.12436804557394966 total_time 723.0\n",
      "episode 4179, reward 1374.0, memory_length 2000, epsilon 0.12374775735888416 total_time 727.0\n",
      "episode 4189, reward 955.0, memory_length 2000, epsilon 0.12313056284419784 total_time 725.0\n",
      "episode 4199, reward 1719.0, memory_length 2000, epsilon 0.12251644659999568 total_time 722.0\n",
      "episode 4209, reward 1417.0, memory_length 2000, epsilon 0.12190539327333952 total_time 722.0\n",
      "episode 4219, reward 1607.0, memory_length 2000, epsilon 0.12129738758786451 total_time 721.0\n",
      "episode 4229, reward 1389.0, memory_length 2000, epsilon 0.12069241434339678 total_time 725.0\n",
      "episode 4239, reward 1761.0, memory_length 2000, epsilon 0.12009045841557368 total_time 729.0\n",
      "episode 4249, reward 1404.0, memory_length 2000, epsilon 0.1194915047554657 total_time 726.0\n",
      "episode 4259, reward 998.0, memory_length 2000, epsilon 0.11889553838920008 total_time 727.0\n",
      "episode 4269, reward 1307.0, memory_length 2000, epsilon 0.11830254441758672 total_time 725.0\n",
      "episode 4279, reward 1823.0, memory_length 2000, epsilon 0.1177125080157454 total_time 728.0\n",
      "episode 4289, reward 1499.0, memory_length 2000, epsilon 0.11712541443273533 total_time 729.0\n",
      "episode 4299, reward 1125.0, memory_length 2000, epsilon 0.11654124899118631 total_time 721.0\n",
      "episode 4309, reward 1937.0, memory_length 2000, epsilon 0.115959997086932 total_time 727.0\n",
      "episode 4319, reward 1282.0, memory_length 2000, epsilon 0.11538164418864444 total_time 721.0\n",
      "episode 4329, reward 1202.0, memory_length 2000, epsilon 0.11480617583747106 total_time 721.0\n",
      "episode 4339, reward 1065.0, memory_length 2000, epsilon 0.11423357764667307 total_time 726.0\n",
      "episode 4349, reward 1098.0, memory_length 2000, epsilon 0.11366383530126595 total_time 728.0\n",
      "episode 4359, reward 851.0, memory_length 2000, epsilon 0.11309693455766137 total_time 727.0\n",
      "episode 4369, reward 1189.0, memory_length 2000, epsilon 0.1125328612433112 total_time 730.0\n",
      "episode 4379, reward 1136.0, memory_length 2000, epsilon 0.11197160125635315 total_time 721.0\n",
      "episode 4389, reward 915.0, memory_length 2000, epsilon 0.11141314056525843 total_time 727.0\n",
      "episode 4399, reward 1042.0, memory_length 2000, epsilon 0.11085746520848058 total_time 727.0\n",
      "episode 4409, reward 1310.0, memory_length 2000, epsilon 0.11030456129410682 total_time 721.0\n",
      "episode 4419, reward 935.0, memory_length 2000, epsilon 0.10975441499951036 total_time 722.0\n",
      "episode 4429, reward 1482.0, memory_length 2000, epsilon 0.10920701257100535 total_time 723.0\n",
      "episode 4439, reward 1545.0, memory_length 2000, epsilon 0.10866234032350246 total_time 722.0\n",
      "episode 4449, reward 1467.0, memory_length 2000, epsilon 0.10812038464016717 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4459, reward 875.0, memory_length 2000, epsilon 0.10758113197207911 total_time 724.0\n",
      "episode 4469, reward 1064.0, memory_length 2000, epsilon 0.10704456883789358 total_time 725.0\n",
      "episode 4479, reward 1264.0, memory_length 2000, epsilon 0.10651068182350425 total_time 723.0\n",
      "episode 4489, reward 1501.0, memory_length 2000, epsilon 0.10597945758170793 total_time 724.0\n",
      "episode 4499, reward 1719.0, memory_length 2000, epsilon 0.10545088283187094 total_time 721.0\n",
      "episode 4509, reward 1503.0, memory_length 2000, epsilon 0.10492494435959693 total_time 721.0\n",
      "episode 4519, reward 1571.0, memory_length 2000, epsilon 0.1044016290163968 total_time 726.0\n",
      "episode 4529, reward 1410.0, memory_length 2000, epsilon 0.10388092371935967 total_time 726.0\n",
      "episode 4539, reward 1349.0, memory_length 2000, epsilon 0.103362815450826 total_time 722.0\n",
      "episode 4549, reward 1436.0, memory_length 2000, epsilon 0.10284729125806202 total_time 721.0\n",
      "episode 4559, reward 1692.0, memory_length 2000, epsilon 0.1023343382529362 total_time 724.0\n",
      "episode 4569, reward 1666.0, memory_length 2000, epsilon 0.10182394361159659 total_time 723.0\n",
      "episode 4579, reward 1711.0, memory_length 2000, epsilon 0.10131609457415063 total_time 722.0\n",
      "episode 4589, reward 1611.0, memory_length 2000, epsilon 0.10081077844434586 total_time 721.0\n",
      "episode 4599, reward 1611.0, memory_length 2000, epsilon 0.10030798258925279 total_time 724.0\n",
      "episode 4609, reward 1722.0, memory_length 2000, epsilon 0.09980769443894884 total_time 721.0\n",
      "episode 4619, reward 1332.0, memory_length 2000, epsilon 0.0993099014862042 total_time 721.0\n",
      "episode 4629, reward 1621.0, memory_length 2000, epsilon 0.09881459128616905 total_time 724.0\n",
      "episode 4639, reward 783.0, memory_length 2000, epsilon 0.09832175145606269 total_time 726.0\n",
      "episode 4649, reward 1620.0, memory_length 2000, epsilon 0.09783136967486368 total_time 728.0\n",
      "episode 4659, reward 1223.0, memory_length 2000, epsilon 0.09734343368300191 total_time 726.0\n",
      "episode 4669, reward 1332.0, memory_length 2000, epsilon 0.09685793128205217 total_time 721.0\n",
      "episode 4679, reward 1819.0, memory_length 2000, epsilon 0.09637485033442919 total_time 725.0\n",
      "episode 4689, reward 2108.0, memory_length 2000, epsilon 0.0958941787630841 total_time 722.0\n",
      "episode 4699, reward 1363.0, memory_length 2000, epsilon 0.0954159045512026 total_time 723.0\n",
      "episode 4709, reward 1697.0, memory_length 2000, epsilon 0.0949400157419044 total_time 724.0\n",
      "episode 4719, reward 1953.0, memory_length 2000, epsilon 0.09446650043794459 total_time 728.0\n",
      "episode 4729, reward 1658.0, memory_length 2000, epsilon 0.09399534680141587 total_time 724.0\n",
      "episode 4739, reward 1035.0, memory_length 2000, epsilon 0.09352654305345277 total_time 729.0\n",
      "episode 4749, reward 1420.0, memory_length 2000, epsilon 0.0930600774739372 total_time 724.0\n",
      "episode 4759, reward 1822.0, memory_length 2000, epsilon 0.09259593840120531 total_time 723.0\n",
      "episode 4769, reward 1220.0, memory_length 2000, epsilon 0.0921341142317562 total_time 723.0\n",
      "episode 4779, reward 1206.0, memory_length 2000, epsilon 0.09167459341996154 total_time 726.0\n",
      "episode 4789, reward 1129.0, memory_length 2000, epsilon 0.0912173644777771 total_time 723.0\n",
      "episode 4799, reward 1080.0, memory_length 2000, epsilon 0.09076241597445547 total_time 721.0\n",
      "episode 4809, reward 1054.0, memory_length 2000, epsilon 0.09030973653626047 total_time 729.0\n",
      "episode 4819, reward 1039.0, memory_length 2000, epsilon 0.0898593148461825 total_time 722.0\n",
      "episode 4829, reward 1266.0, memory_length 2000, epsilon 0.08941113964365587 total_time 730.0\n",
      "episode 4839, reward 1766.0, memory_length 2000, epsilon 0.08896519972427712 total_time 728.0\n",
      "episode 4849, reward 1673.0, memory_length 2000, epsilon 0.08852148393952511 total_time 721.0\n",
      "episode 4859, reward 1262.0, memory_length 2000, epsilon 0.08807998119648211 total_time 725.0\n",
      "episode 4869, reward 1953.0, memory_length 2000, epsilon 0.0876406804575565 total_time 730.0\n",
      "episode 4879, reward 1360.0, memory_length 2000, epsilon 0.08720357074020693 total_time 729.0\n",
      "episode 4889, reward 1673.0, memory_length 2000, epsilon 0.08676864111666777 total_time 727.0\n",
      "episode 4899, reward 1644.0, memory_length 2000, epsilon 0.0863358807136757 total_time 721.0\n",
      "episode 4909, reward 1505.0, memory_length 2000, epsilon 0.08590527871219816 total_time 722.0\n",
      "episode 4919, reward 1544.0, memory_length 2000, epsilon 0.08547682434716262 total_time 726.0\n",
      "episode 4929, reward 1795.0, memory_length 2000, epsilon 0.08505050690718771 total_time 723.0\n",
      "episode 4939, reward 1852.0, memory_length 2000, epsilon 0.08462631573431521 total_time 721.0\n",
      "episode 4949, reward 1725.0, memory_length 2000, epsilon 0.08420424022374369 total_time 729.0\n",
      "episode 4959, reward 1263.0, memory_length 2000, epsilon 0.08378426982356336 total_time 722.0\n",
      "episode 4969, reward 1422.0, memory_length 2000, epsilon 0.08336639403449243 total_time 729.0\n",
      "episode 4979, reward 1548.0, memory_length 2000, epsilon 0.08295060240961435 total_time 723.0\n",
      "episode 4989, reward 1512.0, memory_length 2000, epsilon 0.08253688455411688 total_time 721.0\n",
      "episode 4999, reward 1584.0, memory_length 2000, epsilon 0.08212523012503205 total_time 725.0\n",
      "Saving Model 5000\n",
      "episode 5009, reward 1685.0, memory_length 2000, epsilon 0.08171562883097767 total_time 722.0\n",
      "episode 5019, reward 529.0, memory_length 2000, epsilon 0.08130807043190014 total_time 727.0\n",
      "episode 5029, reward 1705.0, memory_length 2000, epsilon 0.0809025447388182 total_time 723.0\n",
      "episode 5039, reward 1615.0, memory_length 2000, epsilon 0.08049904161356838 total_time 723.0\n",
      "episode 5049, reward 1370.0, memory_length 2000, epsilon 0.08009755096855156 total_time 725.0\n",
      "episode 5059, reward 1754.0, memory_length 2000, epsilon 0.07969806276648073 total_time 724.0\n",
      "episode 5069, reward 1104.0, memory_length 2000, epsilon 0.07930056702013001 total_time 724.0\n",
      "episode 5079, reward 1690.0, memory_length 2000, epsilon 0.07890505379208503 total_time 723.0\n",
      "episode 5089, reward 1414.0, memory_length 2000, epsilon 0.07851151319449445 total_time 725.0\n",
      "episode 5099, reward 1715.0, memory_length 2000, epsilon 0.07811993538882292 total_time 730.0\n",
      "episode 5109, reward 1158.0, memory_length 2000, epsilon 0.07773031058560487 total_time 724.0\n",
      "episode 5119, reward 1478.0, memory_length 2000, epsilon 0.07734262904419989 total_time 722.0\n",
      "episode 5129, reward 1833.0, memory_length 2000, epsilon 0.07695688107254926 total_time 726.0\n",
      "episode 5139, reward 1295.0, memory_length 2000, epsilon 0.07657305702693368 total_time 723.0\n",
      "episode 5149, reward 1580.0, memory_length 2000, epsilon 0.07619114731173192 total_time 731.0\n",
      "episode 5159, reward 1532.0, memory_length 2000, epsilon 0.07581114237918127 total_time 725.0\n",
      "episode 5169, reward 1179.0, memory_length 2000, epsilon 0.07543303272913854 total_time 729.0\n",
      "episode 5179, reward 1787.0, memory_length 2000, epsilon 0.07505680890884289 total_time 730.0\n",
      "episode 5189, reward 1670.0, memory_length 2000, epsilon 0.07468246151267918 total_time 726.0\n",
      "episode 5199, reward 1405.0, memory_length 2000, epsilon 0.074309981181943 total_time 726.0\n",
      "episode 5209, reward 1548.0, memory_length 2000, epsilon 0.07393935860460665 total_time 727.0\n",
      "episode 5219, reward 1265.0, memory_length 2000, epsilon 0.07357058451508645 total_time 721.0\n",
      "episode 5229, reward 1845.0, memory_length 2000, epsilon 0.07320364969401096 total_time 721.0\n",
      "episode 5239, reward 1686.0, memory_length 2000, epsilon 0.07283854496799048 total_time 723.0\n",
      "episode 5249, reward 1416.0, memory_length 2000, epsilon 0.0724752612093879 total_time 724.0\n",
      "episode 5259, reward 1253.0, memory_length 2000, epsilon 0.07211378933609025 total_time 725.0\n",
      "episode 5269, reward 1594.0, memory_length 2000, epsilon 0.07175412031128199 total_time 724.0\n",
      "episode 5279, reward 1503.0, memory_length 2000, epsilon 0.0713962451432187 total_time 729.0\n",
      "episode 5289, reward 1260.0, memory_length 2000, epsilon 0.07104015488500255 total_time 722.0\n",
      "episode 5299, reward 1445.0, memory_length 2000, epsilon 0.07068584063435851 total_time 725.0\n",
      "episode 5309, reward 1620.0, memory_length 2000, epsilon 0.07033329353341192 total_time 725.0\n",
      "episode 5319, reward 1414.0, memory_length 2000, epsilon 0.06998250476846683 total_time 733.0\n",
      "episode 5329, reward 1675.0, memory_length 2000, epsilon 0.0696334655697859 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5339, reward 1338.0, memory_length 2000, epsilon 0.06928616721137094 total_time 728.0\n",
      "episode 5349, reward 1286.0, memory_length 2000, epsilon 0.06894060101074495 total_time 723.0\n",
      "episode 5359, reward 1860.0, memory_length 2000, epsilon 0.06859675832873488 total_time 723.0\n",
      "episode 5369, reward 1697.0, memory_length 2000, epsilon 0.06825463056925578 total_time 731.0\n",
      "episode 5379, reward 1772.0, memory_length 2000, epsilon 0.06791420917909581 total_time 722.0\n",
      "episode 5389, reward 1548.0, memory_length 2000, epsilon 0.06757548564770255 total_time 723.0\n",
      "episode 5399, reward 1219.0, memory_length 2000, epsilon 0.06723845150697004 total_time 723.0\n",
      "episode 5409, reward 1593.0, memory_length 2000, epsilon 0.06690309833102723 total_time 731.0\n",
      "episode 5419, reward 1915.0, memory_length 2000, epsilon 0.06656941773602718 total_time 726.0\n",
      "episode 5429, reward 1479.0, memory_length 2000, epsilon 0.06623740137993772 total_time 723.0\n",
      "episode 5439, reward 1863.0, memory_length 2000, epsilon 0.06590704096233263 total_time 721.0\n",
      "episode 5449, reward 1787.0, memory_length 2000, epsilon 0.06557832822418427 total_time 727.0\n",
      "episode 5459, reward 2021.0, memory_length 2000, epsilon 0.06525125494765702 total_time 721.0\n",
      "episode 5469, reward 2061.0, memory_length 2000, epsilon 0.064925812955902 total_time 721.0\n",
      "episode 5479, reward 1446.0, memory_length 2000, epsilon 0.06460199411285243 total_time 724.0\n",
      "episode 5489, reward 1683.0, memory_length 2000, epsilon 0.06427979032302036 total_time 730.0\n",
      "episode 5499, reward 1820.0, memory_length 2000, epsilon 0.06395919353129426 total_time 725.0\n",
      "episode 5509, reward 1581.0, memory_length 2000, epsilon 0.06364019572273769 total_time 722.0\n",
      "episode 5519, reward 2131.0, memory_length 2000, epsilon 0.06332278892238877 total_time 721.0\n",
      "episode 5529, reward 933.0, memory_length 2000, epsilon 0.06300696519506098 total_time 721.0\n",
      "episode 5539, reward 1643.0, memory_length 2000, epsilon 0.06269271664514467 total_time 724.0\n",
      "episode 5549, reward 1599.0, memory_length 2000, epsilon 0.06238003541640971 total_time 725.0\n",
      "episode 5559, reward 1470.0, memory_length 2000, epsilon 0.06206891369180917 total_time 722.0\n",
      "episode 5569, reward 1106.0, memory_length 2000, epsilon 0.061759343693283675 total_time 721.0\n",
      "episode 5579, reward 1608.0, memory_length 2000, epsilon 0.06145131768156714 total_time 723.0\n",
      "episode 5589, reward 1287.0, memory_length 2000, epsilon 0.061144827955993214 total_time 722.0\n",
      "episode 5599, reward 1339.0, memory_length 2000, epsilon 0.06083986685430284 total_time 721.0\n",
      "episode 5609, reward 1368.0, memory_length 2000, epsilon 0.06053642675245258 total_time 724.0\n",
      "episode 5619, reward 1302.0, memory_length 2000, epsilon 0.06023450006442407 total_time 724.0\n",
      "episode 5629, reward 1144.0, memory_length 2000, epsilon 0.059934079242034345 total_time 721.0\n",
      "episode 5639, reward 1401.0, memory_length 2000, epsilon 0.05963515677474728 total_time 727.0\n",
      "episode 5649, reward 1278.0, memory_length 2000, epsilon 0.05933772518948558 total_time 731.0\n",
      "episode 5659, reward 1809.0, memory_length 2000, epsilon 0.05904177705044413 total_time 726.0\n",
      "episode 5669, reward 1691.0, memory_length 2000, epsilon 0.05874730495890401 total_time 723.0\n",
      "episode 5679, reward 1161.0, memory_length 2000, epsilon 0.05845430155304764 total_time 731.0\n",
      "episode 5689, reward 1658.0, memory_length 2000, epsilon 0.05816275950777461 total_time 724.0\n",
      "episode 5699, reward 1498.0, memory_length 2000, epsilon 0.05787267153451857 total_time 723.0\n",
      "episode 5709, reward 1124.0, memory_length 2000, epsilon 0.05758403038106508 total_time 724.0\n",
      "episode 5719, reward 1386.0, memory_length 2000, epsilon 0.05729682883137031 total_time 725.0\n",
      "episode 5729, reward 1690.0, memory_length 2000, epsilon 0.057011059705380535 total_time 723.0\n",
      "episode 5739, reward 1754.0, memory_length 2000, epsilon 0.05672671585885272 total_time 724.0\n",
      "episode 5749, reward 1693.0, memory_length 2000, epsilon 0.05644379018317588 total_time 729.0\n",
      "episode 5759, reward 1474.0, memory_length 2000, epsilon 0.056162275605193414 total_time 721.0\n",
      "episode 5769, reward 1699.0, memory_length 2000, epsilon 0.05588216508702621 total_time 725.0\n",
      "episode 5779, reward 1653.0, memory_length 2000, epsilon 0.055603451625896715 total_time 729.0\n",
      "episode 5789, reward 1478.0, memory_length 2000, epsilon 0.05532612825395388 total_time 722.0\n",
      "episode 5799, reward 1629.0, memory_length 2000, epsilon 0.055050188038098934 total_time 729.0\n",
      "episode 5809, reward 1449.0, memory_length 2000, epsilon 0.05477562407981217 total_time 726.0\n",
      "episode 5819, reward 1758.0, memory_length 2000, epsilon 0.0545024295149803 total_time 721.0\n",
      "episode 5829, reward 1387.0, memory_length 2000, epsilon 0.054230597513724985 total_time 723.0\n",
      "episode 5839, reward 1647.0, memory_length 2000, epsilon 0.05396012128023198 total_time 722.0\n",
      "episode 5849, reward 1402.0, memory_length 2000, epsilon 0.05369099405258145 total_time 722.0\n",
      "episode 5859, reward 1777.0, memory_length 2000, epsilon 0.05342320910257864 total_time 722.0\n",
      "episode 5869, reward 1648.0, memory_length 2000, epsilon 0.05315675973558585 total_time 730.0\n",
      "episode 5879, reward 1299.0, memory_length 2000, epsilon 0.05289163929035501 total_time 725.0\n",
      "episode 5889, reward 2003.0, memory_length 2000, epsilon 0.05262784113886122 total_time 723.0\n",
      "episode 5899, reward 1296.0, memory_length 2000, epsilon 0.05236535868613695 total_time 721.0\n",
      "episode 5909, reward 1838.0, memory_length 2000, epsilon 0.0521041853701072 total_time 725.0\n",
      "episode 5919, reward 1044.0, memory_length 2000, epsilon 0.05184431466142543 total_time 722.0\n",
      "episode 5929, reward 1920.0, memory_length 2000, epsilon 0.051585740063310445 total_time 725.0\n",
      "episode 5939, reward 1697.0, memory_length 2000, epsilon 0.051328455111383814 total_time 730.0\n",
      "episode 5949, reward 1638.0, memory_length 2000, epsilon 0.05107245337350832 total_time 725.0\n",
      "episode 5959, reward 1382.0, memory_length 2000, epsilon 0.05081772844962717 total_time 730.0\n",
      "episode 5969, reward 2030.0, memory_length 2000, epsilon 0.05056427397160404 total_time 732.0\n",
      "episode 5979, reward 1755.0, memory_length 2000, epsilon 0.05031208360306376 total_time 728.0\n",
      "episode 5989, reward 1285.0, memory_length 2000, epsilon 0.050061151039233975 total_time 726.0\n",
      "episode 5999, reward 1134.0, memory_length 2000, epsilon 0.049811470006787505 total_time 733.0\n",
      "Saving Model 6000\n",
      "episode 6009, reward 1620.0, memory_length 2000, epsilon 0.04956303426368557 total_time 731.0\n",
      "episode 6019, reward 1340.0, memory_length 2000, epsilon 0.04931583759902165 total_time 724.0\n",
      "episode 6029, reward 1773.0, memory_length 2000, epsilon 0.049069873832866234 total_time 724.0\n",
      "episode 6039, reward 1691.0, memory_length 2000, epsilon 0.04882513681611236 total_time 721.0\n",
      "episode 6049, reward 1198.0, memory_length 2000, epsilon 0.04858162043032186 total_time 723.0\n",
      "episode 6059, reward 1386.0, memory_length 2000, epsilon 0.04833931858757242 total_time 722.0\n",
      "episode 6069, reward 1682.0, memory_length 2000, epsilon 0.04809822523030535 total_time 724.0\n",
      "episode 6079, reward 1881.0, memory_length 2000, epsilon 0.04785833433117416 total_time 729.0\n",
      "episode 6089, reward 1505.0, memory_length 2000, epsilon 0.04761963989289384 total_time 724.0\n",
      "episode 6099, reward 1665.0, memory_length 2000, epsilon 0.04738213594809106 total_time 722.0\n",
      "episode 6109, reward 1103.0, memory_length 2000, epsilon 0.04714581655915481 total_time 721.0\n",
      "episode 6119, reward 1357.0, memory_length 2000, epsilon 0.04691067581808805 total_time 721.0\n",
      "episode 6129, reward 1521.0, memory_length 2000, epsilon 0.04667670784635998 total_time 722.0\n",
      "episode 6139, reward 1856.0, memory_length 2000, epsilon 0.046443906794759175 total_time 722.0\n",
      "episode 6149, reward 902.0, memory_length 2000, epsilon 0.046212266843247196 total_time 726.0\n",
      "episode 6159, reward 1061.0, memory_length 2000, epsilon 0.04598178220081319 total_time 722.0\n",
      "episode 6169, reward 1526.0, memory_length 2000, epsilon 0.04575244710532907 total_time 724.0\n",
      "episode 6179, reward 1711.0, memory_length 2000, epsilon 0.045524255823405545 total_time 722.0\n",
      "episode 6189, reward 1190.0, memory_length 2000, epsilon 0.04529720265024866 total_time 723.0\n",
      "episode 6199, reward 1787.0, memory_length 2000, epsilon 0.045071281909517265 total_time 731.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6209, reward 1360.0, memory_length 2000, epsilon 0.04484648795318105 total_time 725.0\n",
      "episode 6219, reward 1319.0, memory_length 2000, epsilon 0.04462281516137944 total_time 723.0\n",
      "episode 6229, reward 1508.0, memory_length 2000, epsilon 0.044400257942280974 total_time 724.0\n",
      "episode 6239, reward 1746.0, memory_length 2000, epsilon 0.04417881073194358 total_time 730.0\n",
      "episode 6249, reward 1413.0, memory_length 2000, epsilon 0.04395846799417545 total_time 726.0\n",
      "episode 6259, reward 1892.0, memory_length 2000, epsilon 0.043739224220396694 total_time 724.0\n",
      "episode 6269, reward 1419.0, memory_length 2000, epsilon 0.04352107392950154 total_time 725.0\n",
      "episode 6279, reward 1743.0, memory_length 2000, epsilon 0.04330401166772134 total_time 721.0\n",
      "episode 6289, reward 1382.0, memory_length 2000, epsilon 0.04308803200848826 total_time 726.0\n",
      "episode 6299, reward 1514.0, memory_length 2000, epsilon 0.042873129552299535 total_time 721.0\n",
      "episode 6309, reward 996.0, memory_length 2000, epsilon 0.04265929892658262 total_time 728.0\n",
      "episode 6319, reward 1859.0, memory_length 2000, epsilon 0.04244653478556071 total_time 732.0\n",
      "episode 6329, reward 1475.0, memory_length 2000, epsilon 0.042234831810119194 total_time 726.0\n",
      "episode 6339, reward 1404.0, memory_length 2000, epsilon 0.04202418470767265 total_time 730.0\n",
      "episode 6349, reward 1179.0, memory_length 2000, epsilon 0.04181458821203258 total_time 721.0\n",
      "episode 6359, reward 1354.0, memory_length 2000, epsilon 0.04160603708327565 total_time 721.0\n",
      "episode 6369, reward 1441.0, memory_length 2000, epsilon 0.041398526107612785 total_time 724.0\n",
      "episode 6379, reward 1858.0, memory_length 2000, epsilon 0.041192050097258764 total_time 723.0\n",
      "episode 6389, reward 1757.0, memory_length 2000, epsilon 0.04098660389030262 total_time 728.0\n",
      "episode 6399, reward 1653.0, memory_length 2000, epsilon 0.04078218235057845 total_time 726.0\n",
      "episode 6409, reward 1292.0, memory_length 2000, epsilon 0.04057878036753712 total_time 721.0\n",
      "episode 6419, reward 1559.0, memory_length 2000, epsilon 0.04037639285611844 total_time 726.0\n",
      "episode 6429, reward 1274.0, memory_length 2000, epsilon 0.04017501475662412 total_time 725.0\n",
      "episode 6439, reward 1487.0, memory_length 2000, epsilon 0.03997464103459117 total_time 726.0\n",
      "episode 6449, reward 1231.0, memory_length 2000, epsilon 0.039775266680666096 total_time 721.0\n",
      "episode 6459, reward 1660.0, memory_length 2000, epsilon 0.039576886710479646 total_time 721.0\n",
      "episode 6469, reward 1724.0, memory_length 2000, epsilon 0.03937949616452228 total_time 728.0\n",
      "episode 6479, reward 1281.0, memory_length 2000, epsilon 0.03918309010802005 total_time 731.0\n",
      "episode 6489, reward 1319.0, memory_length 2000, epsilon 0.03898766363081129 total_time 730.0\n",
      "episode 6499, reward 1100.0, memory_length 2000, epsilon 0.0387932118472239 total_time 722.0\n",
      "episode 6509, reward 1843.0, memory_length 2000, epsilon 0.0385997298959532 total_time 723.0\n",
      "episode 6519, reward 1805.0, memory_length 2000, epsilon 0.03840721293994029 total_time 723.0\n",
      "episode 6529, reward 1865.0, memory_length 2000, epsilon 0.03821565616625126 total_time 726.0\n",
      "episode 6539, reward 1584.0, memory_length 2000, epsilon 0.03802505478595679 total_time 729.0\n",
      "episode 6549, reward 1756.0, memory_length 2000, epsilon 0.03783540403401242 total_time 721.0\n",
      "episode 6559, reward 1584.0, memory_length 2000, epsilon 0.03764669916913952 total_time 721.0\n",
      "episode 6569, reward 1352.0, memory_length 2000, epsilon 0.037458935473706614 total_time 723.0\n",
      "episode 6579, reward 1573.0, memory_length 2000, epsilon 0.03727210825361153 total_time 723.0\n",
      "episode 6589, reward 1785.0, memory_length 2000, epsilon 0.03708621283816403 total_time 721.0\n",
      "episode 6599, reward 1945.0, memory_length 2000, epsilon 0.03690124457996908 total_time 724.0\n",
      "episode 6609, reward 1589.0, memory_length 2000, epsilon 0.036717198854810576 total_time 725.0\n",
      "episode 6619, reward 1112.0, memory_length 2000, epsilon 0.036534071061535785 total_time 728.0\n",
      "episode 6629, reward 1559.0, memory_length 2000, epsilon 0.03635185662194034 total_time 725.0\n",
      "episode 6639, reward 1865.0, memory_length 2000, epsilon 0.03617055098065379 total_time 724.0\n",
      "episode 6649, reward 1149.0, memory_length 2000, epsilon 0.03599014960502563 total_time 721.0\n",
      "episode 6659, reward 1553.0, memory_length 2000, epsilon 0.035810647985012094 total_time 730.0\n",
      "episode 6669, reward 1195.0, memory_length 2000, epsilon 0.03563204163306331 total_time 721.0\n",
      "episode 6679, reward 1476.0, memory_length 2000, epsilon 0.035454326084011195 total_time 722.0\n",
      "episode 6689, reward 1809.0, memory_length 2000, epsilon 0.03527749689495777 total_time 722.0\n",
      "episode 6699, reward 1230.0, memory_length 2000, epsilon 0.03510154964516409 total_time 722.0\n",
      "episode 6709, reward 1585.0, memory_length 2000, epsilon 0.03492647993593973 total_time 729.0\n",
      "episode 6719, reward 2035.0, memory_length 2000, epsilon 0.034752283390532865 total_time 729.0\n",
      "episode 6729, reward 1352.0, memory_length 2000, epsilon 0.03457895565402079 total_time 723.0\n",
      "episode 6739, reward 1640.0, memory_length 2000, epsilon 0.03440649239320105 total_time 722.0\n",
      "episode 6749, reward 1818.0, memory_length 2000, epsilon 0.03423488929648313 total_time 728.0\n",
      "episode 6759, reward 1674.0, memory_length 2000, epsilon 0.0340641420737807 total_time 722.0\n",
      "episode 6769, reward 1121.0, memory_length 2000, epsilon 0.0338942464564043 total_time 725.0\n",
      "episode 6779, reward 1602.0, memory_length 2000, epsilon 0.03372519819695464 total_time 726.0\n",
      "episode 6789, reward 1236.0, memory_length 2000, epsilon 0.03355699306921642 total_time 726.0\n",
      "episode 6799, reward 1580.0, memory_length 2000, epsilon 0.03338962686805266 total_time 725.0\n",
      "episode 6809, reward 1292.0, memory_length 2000, epsilon 0.033223095409299686 total_time 728.0\n",
      "episode 6819, reward 1352.0, memory_length 2000, epsilon 0.03305739452966231 total_time 721.0\n",
      "episode 6829, reward 1161.0, memory_length 2000, epsilon 0.032892520086609915 total_time 727.0\n",
      "episode 6839, reward 1840.0, memory_length 2000, epsilon 0.03272846795827282 total_time 721.0\n",
      "episode 6849, reward 1900.0, memory_length 2000, epsilon 0.0325652340433393 total_time 727.0\n",
      "episode 6859, reward 1057.0, memory_length 2000, epsilon 0.03240281426095298 total_time 724.0\n",
      "episode 6869, reward 1597.0, memory_length 2000, epsilon 0.03224120455061084 total_time 723.0\n",
      "episode 6879, reward 1391.0, memory_length 2000, epsilon 0.03208040087206167 total_time 721.0\n",
      "episode 6889, reward 1773.0, memory_length 2000, epsilon 0.03192039920520517 total_time 725.0\n",
      "episode 6899, reward 1697.0, memory_length 2000, epsilon 0.03176119554999133 total_time 727.0\n",
      "episode 6909, reward 1454.0, memory_length 2000, epsilon 0.031602785926320466 total_time 730.0\n",
      "episode 6919, reward 1688.0, memory_length 2000, epsilon 0.03144516637394371 total_time 727.0\n",
      "episode 6929, reward 1400.0, memory_length 2000, epsilon 0.03128833295236411 total_time 726.0\n",
      "episode 6939, reward 1388.0, memory_length 2000, epsilon 0.031132281740737917 total_time 726.0\n",
      "episode 6949, reward 938.0, memory_length 2000, epsilon 0.030977008837776713 total_time 725.0\n",
      "episode 6959, reward 1935.0, memory_length 2000, epsilon 0.030822510361649826 total_time 724.0\n",
      "episode 6969, reward 963.0, memory_length 2000, epsilon 0.030668782449887338 total_time 721.0\n",
      "episode 6979, reward 1996.0, memory_length 2000, epsilon 0.03051582125928343 total_time 724.0\n",
      "episode 6989, reward 1762.0, memory_length 2000, epsilon 0.030363622965800367 total_time 726.0\n",
      "episode 6999, reward 1710.0, memory_length 2000, epsilon 0.030212183764472877 total_time 731.0\n",
      "Saving Model 7000\n",
      "episode 7009, reward 2053.0, memory_length 2000, epsilon 0.030061499869313068 total_time 726.0\n",
      "episode 7019, reward 1659.0, memory_length 2000, epsilon 0.029911567513215692 total_time 724.0\n",
      "episode 7029, reward 1798.0, memory_length 2000, epsilon 0.029762382947864045 total_time 725.0\n",
      "episode 7039, reward 1557.0, memory_length 2000, epsilon 0.029613942443636205 total_time 721.0\n",
      "episode 7049, reward 1593.0, memory_length 2000, epsilon 0.029466242289511866 total_time 729.0\n",
      "episode 7059, reward 1296.0, memory_length 2000, epsilon 0.029319278792979464 total_time 723.0\n",
      "episode 7069, reward 1801.0, memory_length 2000, epsilon 0.029173048279943936 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7079, reward 1460.0, memory_length 2000, epsilon 0.029027547094634832 total_time 724.0\n",
      "episode 7089, reward 1515.0, memory_length 2000, epsilon 0.02888277159951494 total_time 725.0\n",
      "episode 7099, reward 1986.0, memory_length 2000, epsilon 0.028738718175189356 total_time 728.0\n",
      "episode 7109, reward 1700.0, memory_length 2000, epsilon 0.028595383220314963 total_time 721.0\n",
      "episode 7119, reward 1674.0, memory_length 2000, epsilon 0.02845276315151042 total_time 731.0\n",
      "episode 7129, reward 2095.0, memory_length 2000, epsilon 0.028310854403266573 total_time 722.0\n",
      "episode 7139, reward 1818.0, memory_length 2000, epsilon 0.028169653427857343 total_time 721.0\n",
      "episode 7149, reward 2041.0, memory_length 2000, epsilon 0.028029156695250978 total_time 721.0\n",
      "episode 7159, reward 1972.0, memory_length 2000, epsilon 0.027889360693021847 total_time 725.0\n",
      "episode 7169, reward 1467.0, memory_length 2000, epsilon 0.027750261926262603 total_time 725.0\n",
      "episode 7179, reward 1087.0, memory_length 2000, epsilon 0.027611856917496857 total_time 731.0\n",
      "episode 7189, reward 1657.0, memory_length 2000, epsilon 0.027474142206592167 total_time 724.0\n",
      "episode 7199, reward 1206.0, memory_length 2000, epsilon 0.027337114350673587 total_time 722.0\n",
      "episode 7209, reward 1818.0, memory_length 2000, epsilon 0.02720076992403757 total_time 723.0\n",
      "episode 7219, reward 1139.0, memory_length 2000, epsilon 0.027065105518066374 total_time 725.0\n",
      "episode 7229, reward 1320.0, memory_length 2000, epsilon 0.026930117741142772 total_time 722.0\n",
      "episode 7239, reward 1606.0, memory_length 2000, epsilon 0.026795803218565308 total_time 724.0\n",
      "episode 7249, reward 1486.0, memory_length 2000, epsilon 0.026662158592463917 total_time 736.0\n",
      "episode 7259, reward 1935.0, memory_length 2000, epsilon 0.026529180521716 total_time 721.0\n",
      "episode 7269, reward 1107.0, memory_length 2000, epsilon 0.02639686568186286 total_time 725.0\n",
      "episode 7279, reward 1312.0, memory_length 2000, epsilon 0.026265210765026602 total_time 721.0\n",
      "episode 7289, reward 1415.0, memory_length 2000, epsilon 0.02613421247982744 total_time 727.0\n",
      "episode 7299, reward 2185.0, memory_length 2000, epsilon 0.02600386755130144 total_time 724.0\n",
      "episode 7309, reward 1629.0, memory_length 2000, epsilon 0.02587417272081859 total_time 721.0\n",
      "episode 7319, reward 1339.0, memory_length 2000, epsilon 0.02574512474600138 total_time 725.0\n",
      "episode 7329, reward 1797.0, memory_length 2000, epsilon 0.02561672040064371 total_time 721.0\n",
      "episode 7339, reward 1917.0, memory_length 2000, epsilon 0.025488956474630255 total_time 721.0\n",
      "episode 7349, reward 1559.0, memory_length 2000, epsilon 0.025361829773856225 total_time 722.0\n",
      "episode 7359, reward 1445.0, memory_length 2000, epsilon 0.02523533712014747 total_time 723.0\n",
      "episode 7369, reward 1550.0, memory_length 2000, epsilon 0.02510947535118106 total_time 722.0\n",
      "episode 7379, reward 1456.0, memory_length 2000, epsilon 0.024984241320406206 total_time 721.0\n",
      "episode 7389, reward 1581.0, memory_length 2000, epsilon 0.024859631896965637 total_time 726.0\n",
      "episode 7399, reward 1717.0, memory_length 2000, epsilon 0.02473564396561726 total_time 724.0\n",
      "episode 7409, reward 1244.0, memory_length 2000, epsilon 0.024612274426656346 total_time 728.0\n",
      "episode 7419, reward 1729.0, memory_length 2000, epsilon 0.02448952019583798 total_time 721.0\n",
      "episode 7429, reward 2026.0, memory_length 2000, epsilon 0.024367378204300013 total_time 726.0\n",
      "episode 7439, reward 1459.0, memory_length 2000, epsilon 0.024245845398486288 total_time 724.0\n",
      "episode 7449, reward 1455.0, memory_length 2000, epsilon 0.024124918740070334 total_time 727.0\n",
      "episode 7459, reward 1238.0, memory_length 2000, epsilon 0.024004595205879373 total_time 725.0\n",
      "episode 7469, reward 1349.0, memory_length 2000, epsilon 0.023884871787818816 total_time 722.0\n",
      "episode 7479, reward 1800.0, memory_length 2000, epsilon 0.023765745492796957 total_time 721.0\n",
      "episode 7489, reward 1800.0, memory_length 2000, epsilon 0.023647213342650217 total_time 726.0\n",
      "episode 7499, reward 1515.0, memory_length 2000, epsilon 0.023529272374068662 total_time 723.0\n",
      "episode 7509, reward 1431.0, memory_length 2000, epsilon 0.02341191963852195 total_time 722.0\n",
      "episode 7519, reward 1420.0, memory_length 2000, epsilon 0.023295152202185577 total_time 726.0\n",
      "episode 7529, reward 1680.0, memory_length 2000, epsilon 0.023178967145867545 total_time 722.0\n",
      "episode 7539, reward 1517.0, memory_length 2000, epsilon 0.02306336156493539 total_time 725.0\n",
      "episode 7549, reward 1783.0, memory_length 2000, epsilon 0.022948332569243588 total_time 721.0\n",
      "episode 7559, reward 1395.0, memory_length 2000, epsilon 0.02283387728306124 total_time 722.0\n",
      "episode 7569, reward 1390.0, memory_length 2000, epsilon 0.022719992845000238 total_time 723.0\n",
      "episode 7579, reward 1636.0, memory_length 2000, epsilon 0.022606676407943692 total_time 726.0\n",
      "episode 7589, reward 1403.0, memory_length 2000, epsilon 0.022493925138974767 total_time 723.0\n",
      "episode 7599, reward 1793.0, memory_length 2000, epsilon 0.022381736219305885 total_time 727.0\n",
      "episode 7609, reward 1432.0, memory_length 2000, epsilon 0.022270106844208205 total_time 728.0\n",
      "episode 7619, reward 1216.0, memory_length 2000, epsilon 0.02215903422294153 total_time 724.0\n",
      "episode 7629, reward 1411.0, memory_length 2000, epsilon 0.022048515578684535 total_time 721.0\n",
      "episode 7639, reward 1745.0, memory_length 2000, epsilon 0.021938548148465385 total_time 722.0\n",
      "episode 7649, reward 1504.0, memory_length 2000, epsilon 0.02182912918309257 total_time 724.0\n",
      "episode 7659, reward 1797.0, memory_length 2000, epsilon 0.021720255947086275 total_time 723.0\n",
      "episode 7669, reward 1323.0, memory_length 2000, epsilon 0.02161192571860991 total_time 721.0\n",
      "episode 7679, reward 1503.0, memory_length 2000, epsilon 0.02150413578940214 total_time 721.0\n",
      "episode 7689, reward 1703.0, memory_length 2000, epsilon 0.021396883464709117 total_time 723.0\n",
      "episode 7699, reward 1710.0, memory_length 2000, epsilon 0.02129016606321713 total_time 731.0\n",
      "episode 7709, reward 1755.0, memory_length 2000, epsilon 0.02118398091698558 total_time 721.0\n",
      "episode 7719, reward 1596.0, memory_length 2000, epsilon 0.021078325371380293 total_time 726.0\n",
      "episode 7729, reward 1923.0, memory_length 2000, epsilon 0.020973196785007125 total_time 723.0\n",
      "episode 7739, reward 1575.0, memory_length 2000, epsilon 0.020868592529645933 total_time 726.0\n",
      "episode 7749, reward 1251.0, memory_length 2000, epsilon 0.020764509990184882 total_time 721.0\n",
      "episode 7759, reward 1248.0, memory_length 2000, epsilon 0.020660946564555086 total_time 724.0\n",
      "episode 7769, reward 1929.0, memory_length 2000, epsilon 0.020557899663665488 total_time 725.0\n",
      "episode 7779, reward 1633.0, memory_length 2000, epsilon 0.02045536671133821 total_time 722.0\n",
      "episode 7789, reward 1557.0, memory_length 2000, epsilon 0.020353345144244087 total_time 722.0\n",
      "episode 7799, reward 1825.0, memory_length 2000, epsilon 0.020251832411838658 total_time 726.0\n",
      "episode 7809, reward 1573.0, memory_length 2000, epsilon 0.0201508259762983 total_time 722.0\n",
      "episode 7819, reward 1861.0, memory_length 2000, epsilon 0.020050323312456878 total_time 721.0\n",
      "episode 7829, reward 1413.0, memory_length 2000, epsilon 0.019950321907742555 total_time 722.0\n",
      "episode 7839, reward 1859.0, memory_length 2000, epsilon 0.019850819262114995 total_time 722.0\n",
      "episode 7849, reward 1757.0, memory_length 2000, epsilon 0.019751812888002897 total_time 724.0\n",
      "episode 7859, reward 1611.0, memory_length 2000, epsilon 0.019653300310241737 total_time 724.0\n",
      "episode 7869, reward 1533.0, memory_length 2000, epsilon 0.019555279066011948 total_time 725.0\n",
      "episode 7879, reward 1339.0, memory_length 2000, epsilon 0.0194577467047773 total_time 728.0\n",
      "episode 7889, reward 1232.0, memory_length 2000, epsilon 0.01936070078822371 total_time 722.0\n",
      "episode 7899, reward 1242.0, memory_length 2000, epsilon 0.019264138890198193 total_time 721.0\n",
      "episode 7909, reward 1665.0, memory_length 2000, epsilon 0.019168058596648274 total_time 721.0\n",
      "episode 7919, reward 1775.0, memory_length 2000, epsilon 0.0190724575055616 total_time 724.0\n",
      "episode 7929, reward 1682.0, memory_length 2000, epsilon 0.018977333226905934 total_time 723.0\n",
      "episode 7939, reward 1341.0, memory_length 2000, epsilon 0.018882683382569338 total_time 726.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7949, reward 1854.0, memory_length 2000, epsilon 0.018788505606300788 total_time 726.0\n",
      "episode 7959, reward 1184.0, memory_length 2000, epsilon 0.01869479754365095 total_time 721.0\n",
      "episode 7969, reward 1497.0, memory_length 2000, epsilon 0.0186015568519134 total_time 723.0\n",
      "episode 7979, reward 1605.0, memory_length 2000, epsilon 0.018508781200065983 total_time 723.0\n",
      "episode 7989, reward 1236.0, memory_length 2000, epsilon 0.018416468268712564 total_time 727.0\n",
      "episode 7999, reward 1729.0, memory_length 2000, epsilon 0.018324615750025048 total_time 724.0\n",
      "Saving Model 8000\n",
      "episode 8009, reward 1541.0, memory_length 2000, epsilon 0.018233221347685697 total_time 721.0\n",
      "episode 8019, reward 1027.0, memory_length 2000, epsilon 0.018142282776829687 total_time 725.0\n",
      "episode 8029, reward 1252.0, memory_length 2000, epsilon 0.01805179776398801 total_time 729.0\n",
      "episode 8039, reward 1344.0, memory_length 2000, epsilon 0.01796176404703063 total_time 722.0\n",
      "episode 8049, reward 1800.0, memory_length 2000, epsilon 0.017872179375109938 total_time 721.0\n",
      "episode 8059, reward 1031.0, memory_length 2000, epsilon 0.01778304150860445 total_time 721.0\n",
      "episode 8069, reward 1715.0, memory_length 2000, epsilon 0.01769434821906289 total_time 725.0\n",
      "episode 8079, reward 1864.0, memory_length 2000, epsilon 0.017606097289148394 total_time 725.0\n",
      "episode 8089, reward 1364.0, memory_length 2000, epsilon 0.017518286512583105 total_time 728.0\n",
      "episode 8099, reward 1683.0, memory_length 2000, epsilon 0.01743091369409305 total_time 721.0\n",
      "episode 8109, reward 1203.0, memory_length 2000, epsilon 0.017343976649353204 total_time 728.0\n",
      "episode 8119, reward 1242.0, memory_length 2000, epsilon 0.017257473204932924 total_time 726.0\n",
      "episode 8129, reward 1448.0, memory_length 2000, epsilon 0.017171401198241596 total_time 722.0\n",
      "episode 8139, reward 1927.0, memory_length 2000, epsilon 0.017085758477474566 total_time 726.0\n",
      "episode 8149, reward 1843.0, memory_length 2000, epsilon 0.017000542901559345 total_time 723.0\n",
      "episode 8159, reward 1513.0, memory_length 2000, epsilon 0.016915752340102123 total_time 722.0\n",
      "episode 8169, reward 1911.0, memory_length 2000, epsilon 0.01683138467333443 total_time 722.0\n",
      "episode 8179, reward 1386.0, memory_length 2000, epsilon 0.016747437792060213 total_time 725.0\n",
      "episode 8189, reward 1827.0, memory_length 2000, epsilon 0.01666390959760305 total_time 732.0\n",
      "episode 8199, reward 1728.0, memory_length 2000, epsilon 0.016580798001753747 total_time 725.0\n",
      "episode 8209, reward 1418.0, memory_length 2000, epsilon 0.016498100926718072 total_time 725.0\n",
      "episode 8219, reward 1337.0, memory_length 2000, epsilon 0.016415816305064838 total_time 723.0\n",
      "episode 8229, reward 1711.0, memory_length 2000, epsilon 0.016333942079674212 total_time 729.0\n",
      "episode 8239, reward 1944.0, memory_length 2000, epsilon 0.016252476203686316 total_time 730.0\n",
      "episode 8249, reward 1900.0, memory_length 2000, epsilon 0.016171416640449996 total_time 727.0\n",
      "episode 8259, reward 1608.0, memory_length 2000, epsilon 0.01609076136347195 total_time 726.0\n",
      "episode 8269, reward 1667.0, memory_length 2000, epsilon 0.016010508356366054 total_time 724.0\n",
      "episode 8279, reward 1293.0, memory_length 2000, epsilon 0.015930655612802946 total_time 728.0\n",
      "episode 8289, reward 1751.0, memory_length 2000, epsilon 0.01585120113645988 total_time 728.0\n",
      "episode 8299, reward 1357.0, memory_length 2000, epsilon 0.01577214294097081 total_time 724.0\n",
      "episode 8309, reward 1571.0, memory_length 2000, epsilon 0.015693479049876717 total_time 724.0\n",
      "episode 8319, reward 1715.0, memory_length 2000, epsilon 0.015615207496576253 total_time 723.0\n",
      "episode 8329, reward 1514.0, memory_length 2000, epsilon 0.015537326324276499 total_time 728.0\n",
      "episode 8339, reward 1369.0, memory_length 2000, epsilon 0.015459833585944086 total_time 722.0\n",
      "episode 8349, reward 1733.0, memory_length 2000, epsilon 0.015382727344256523 total_time 721.0\n",
      "episode 8359, reward 1883.0, memory_length 2000, epsilon 0.015306005671553751 total_time 721.0\n",
      "episode 8369, reward 1765.0, memory_length 2000, epsilon 0.015229666649789956 total_time 721.0\n",
      "episode 8379, reward 1743.0, memory_length 2000, epsilon 0.015153708370485616 total_time 726.0\n",
      "episode 8389, reward 1207.0, memory_length 2000, epsilon 0.015078128934679799 total_time 724.0\n",
      "episode 8399, reward 1622.0, memory_length 2000, epsilon 0.015002926452882651 total_time 726.0\n",
      "episode 8409, reward 1960.0, memory_length 2000, epsilon 0.014928099045028245 total_time 725.0\n",
      "episode 8419, reward 2166.0, memory_length 2000, epsilon 0.014853644840427468 total_time 724.0\n",
      "episode 8429, reward 1663.0, memory_length 2000, epsilon 0.014779561977721331 total_time 724.0\n",
      "episode 8439, reward 1391.0, memory_length 2000, epsilon 0.014705848604834405 total_time 724.0\n",
      "episode 8449, reward 1593.0, memory_length 2000, epsilon 0.014632502878928533 total_time 733.0\n",
      "episode 8459, reward 1548.0, memory_length 2000, epsilon 0.014559522966356741 total_time 731.0\n",
      "episode 8469, reward 1899.0, memory_length 2000, epsilon 0.014486907042617419 total_time 721.0\n",
      "episode 8479, reward 1842.0, memory_length 2000, epsilon 0.014414653292308677 total_time 728.0\n",
      "episode 8489, reward 1749.0, memory_length 2000, epsilon 0.014342759909083017 total_time 721.0\n",
      "episode 8499, reward 1485.0, memory_length 2000, epsilon 0.014271225095602106 total_time 724.0\n",
      "episode 8509, reward 1814.0, memory_length 2000, epsilon 0.014200047063491879 total_time 730.0\n",
      "episode 8519, reward 2031.0, memory_length 2000, epsilon 0.014129224033297824 total_time 729.0\n",
      "episode 8529, reward 1523.0, memory_length 2000, epsilon 0.014058754234440498 total_time 722.0\n",
      "episode 8539, reward 1677.0, memory_length 2000, epsilon 0.013988635905171262 total_time 723.0\n",
      "episode 8549, reward 1873.0, memory_length 2000, epsilon 0.013918867292528232 total_time 727.0\n",
      "episode 8559, reward 1163.0, memory_length 2000, epsilon 0.013849446652292442 total_time 721.0\n",
      "episode 8569, reward 1775.0, memory_length 2000, epsilon 0.0137803722489443 total_time 726.0\n",
      "episode 8579, reward 1676.0, memory_length 2000, epsilon 0.013711642355620108 total_time 726.0\n",
      "episode 8589, reward 1517.0, memory_length 2000, epsilon 0.013643255254068955 total_time 722.0\n",
      "episode 8599, reward 1164.0, memory_length 2000, epsilon 0.013575209234609741 total_time 731.0\n",
      "episode 8609, reward 1631.0, memory_length 2000, epsilon 0.013507502596088435 total_time 721.0\n",
      "episode 8619, reward 1818.0, memory_length 2000, epsilon 0.013440133645835548 total_time 731.0\n",
      "episode 8629, reward 2008.0, memory_length 2000, epsilon 0.013373100699623814 total_time 729.0\n",
      "episode 8639, reward 1368.0, memory_length 2000, epsilon 0.013306402081626088 total_time 721.0\n",
      "episode 8649, reward 1764.0, memory_length 2000, epsilon 0.013240036124373432 total_time 728.0\n",
      "episode 8659, reward 1134.0, memory_length 2000, epsilon 0.013174001168713484 total_time 721.0\n",
      "episode 8669, reward 1720.0, memory_length 2000, epsilon 0.013108295563768897 total_time 721.0\n",
      "episode 8679, reward 1437.0, memory_length 2000, epsilon 0.013042917666896131 total_time 724.0\n",
      "episode 8689, reward 1681.0, memory_length 2000, epsilon 0.012977865843644357 total_time 726.0\n",
      "episode 8699, reward 1752.0, memory_length 2000, epsilon 0.012913138467714604 total_time 725.0\n",
      "episode 8709, reward 1357.0, memory_length 2000, epsilon 0.012848733920919106 total_time 723.0\n",
      "episode 8719, reward 1661.0, memory_length 2000, epsilon 0.012784650593140833 total_time 725.0\n",
      "episode 8729, reward 1783.0, memory_length 2000, epsilon 0.012720886882293246 total_time 723.0\n",
      "episode 8739, reward 1494.0, memory_length 2000, epsilon 0.012657441194280276 total_time 731.0\n",
      "episode 8749, reward 1556.0, memory_length 2000, epsilon 0.012594311942956406 total_time 722.0\n",
      "episode 8759, reward 1909.0, memory_length 2000, epsilon 0.012531497550087062 total_time 727.0\n",
      "episode 8769, reward 1283.0, memory_length 2000, epsilon 0.012468996445309154 total_time 721.0\n",
      "episode 8779, reward 1927.0, memory_length 2000, epsilon 0.012406807066091805 total_time 729.0\n",
      "episode 8789, reward 1532.0, memory_length 2000, epsilon 0.012344927857697297 total_time 724.0\n",
      "episode 8799, reward 1895.0, memory_length 2000, epsilon 0.012283357273142198 total_time 721.0\n",
      "episode 8809, reward 1932.0, memory_length 2000, epsilon 0.012222093773158674 total_time 723.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8819, reward 1216.0, memory_length 2000, epsilon 0.012161135826156058 total_time 728.0\n",
      "episode 8829, reward 1602.0, memory_length 2000, epsilon 0.01210048190818249 total_time 729.0\n",
      "episode 8839, reward 1571.0, memory_length 2000, epsilon 0.01204013050288686 total_time 731.0\n",
      "episode 8849, reward 1989.0, memory_length 2000, epsilon 0.011980080101480892 total_time 726.0\n",
      "episode 8859, reward 1994.0, memory_length 2000, epsilon 0.011920329202701425 total_time 723.0\n",
      "episode 8869, reward 1605.0, memory_length 2000, epsilon 0.011860876312772876 total_time 721.0\n",
      "episode 8879, reward 1904.0, memory_length 2000, epsilon 0.011801719945369903 total_time 731.0\n",
      "episode 8889, reward 1741.0, memory_length 2000, epsilon 0.011742858621580235 total_time 722.0\n",
      "episode 8899, reward 1630.0, memory_length 2000, epsilon 0.011684290869867704 total_time 723.0\n",
      "episode 8909, reward 1720.0, memory_length 2000, epsilon 0.011626015226035489 total_time 725.0\n",
      "episode 8919, reward 1580.0, memory_length 2000, epsilon 0.011568030233189445 total_time 730.0\n",
      "episode 8929, reward 1872.0, memory_length 2000, epsilon 0.011510334441701735 total_time 730.0\n",
      "episode 8939, reward 1728.0, memory_length 2000, epsilon 0.011452926409174561 total_time 721.0\n",
      "episode 8949, reward 1224.0, memory_length 2000, epsilon 0.011395804700404126 total_time 721.0\n",
      "episode 8959, reward 1837.0, memory_length 2000, epsilon 0.011338967887344734 total_time 724.0\n",
      "episode 8969, reward 1551.0, memory_length 2000, epsilon 0.011282414549073095 total_time 728.0\n",
      "episode 8979, reward 1054.0, memory_length 2000, epsilon 0.011226143271752802 total_time 727.0\n",
      "episode 8989, reward 1721.0, memory_length 2000, epsilon 0.011170152648599007 total_time 723.0\n",
      "episode 8999, reward 1598.0, memory_length 2000, epsilon 0.011114441279843205 total_time 721.0\n",
      "Saving Model 9000\n",
      "episode 9009, reward 1971.0, memory_length 2000, epsilon 0.011059007772698278 total_time 721.0\n",
      "episode 9019, reward 1319.0, memory_length 2000, epsilon 0.011003850741323658 total_time 723.0\n",
      "episode 9029, reward 1332.0, memory_length 2000, epsilon 0.01094896880679069 total_time 722.0\n",
      "episode 9039, reward 1719.0, memory_length 2000, epsilon 0.01089436059704815 total_time 728.0\n",
      "episode 9049, reward 1350.0, memory_length 2000, epsilon 0.010840024746887951 total_time 730.0\n",
      "episode 9059, reward 1654.0, memory_length 2000, epsilon 0.010785959897911 total_time 724.0\n",
      "episode 9069, reward 1868.0, memory_length 2000, epsilon 0.010732164698493278 total_time 724.0\n",
      "episode 9079, reward 1897.0, memory_length 2000, epsilon 0.010678637803751981 total_time 724.0\n",
      "episode 9089, reward 2048.0, memory_length 2000, epsilon 0.010625377875511962 total_time 724.0\n",
      "episode 9099, reward 1266.0, memory_length 2000, epsilon 0.010572383582272233 total_time 722.0\n",
      "episode 9109, reward 1543.0, memory_length 2000, epsilon 0.010519653599172708 total_time 721.0\n",
      "episode 9119, reward 2044.0, memory_length 2000, epsilon 0.010467186607961062 total_time 724.0\n",
      "episode 9129, reward 1961.0, memory_length 2000, epsilon 0.01041498129695978 total_time 722.0\n",
      "episode 9139, reward 1590.0, memory_length 2000, epsilon 0.010363036361033369 total_time 728.0\n",
      "episode 9149, reward 1895.0, memory_length 2000, epsilon 0.010311350501555717 total_time 728.0\n",
      "episode 9159, reward 1468.0, memory_length 2000, epsilon 0.010259922426377662 total_time 724.0\n",
      "episode 9169, reward 1773.0, memory_length 2000, epsilon 0.01020875084979464 total_time 729.0\n",
      "episode 9179, reward 1273.0, memory_length 2000, epsilon 0.010157834492514568 total_time 724.0\n",
      "episode 9189, reward 1489.0, memory_length 2000, epsilon 0.010107172081625863 total_time 725.0\n",
      "episode 9199, reward 1360.0, memory_length 2000, epsilon 0.010056762350565615 total_time 722.0\n",
      "episode 9209, reward 1708.0, memory_length 2000, epsilon 0.010006604039087921 total_time 723.0\n",
      "episode 9219, reward 1220.0, memory_length 2000, epsilon 0.009956695893232382 total_time 722.0\n",
      "episode 9229, reward 1448.0, memory_length 2000, epsilon 0.009907036665292744 total_time 722.0\n",
      "episode 9239, reward 1923.0, memory_length 2000, epsilon 0.009857625113785738 total_time 723.0\n",
      "episode 9249, reward 1683.0, memory_length 2000, epsilon 0.009808460003419995 total_time 726.0\n",
      "episode 9259, reward 1600.0, memory_length 2000, epsilon 0.009759540105065195 total_time 723.0\n",
      "episode 9269, reward 1718.0, memory_length 2000, epsilon 0.009710864195721333 total_time 722.0\n",
      "episode 9279, reward 1229.0, memory_length 2000, epsilon 0.009662431058488137 total_time 729.0\n",
      "episode 9289, reward 1329.0, memory_length 2000, epsilon 0.009614239482534655 total_time 722.0\n",
      "episode 9299, reward 1321.0, memory_length 2000, epsilon 0.009566288263068979 total_time 728.0\n",
      "episode 9309, reward 1491.0, memory_length 2000, epsilon 0.009518576201308117 total_time 723.0\n",
      "episode 9319, reward 1797.0, memory_length 2000, epsilon 0.009471102104448055 total_time 721.0\n",
      "episode 9329, reward 1977.0, memory_length 2000, epsilon 0.009423864785633892 total_time 726.0\n",
      "episode 9339, reward 1548.0, memory_length 2000, epsilon 0.009376863063930195 total_time 721.0\n",
      "episode 9349, reward 1853.0, memory_length 2000, epsilon 0.009330095764291474 total_time 722.0\n",
      "episode 9359, reward 1108.0, memory_length 2000, epsilon 0.009283561717532807 total_time 721.0\n",
      "episode 9369, reward 1845.0, memory_length 2000, epsilon 0.009237259760300594 total_time 729.0\n",
      "episode 9379, reward 1311.0, memory_length 2000, epsilon 0.009191188735043496 total_time 728.0\n",
      "episode 9389, reward 2159.0, memory_length 2000, epsilon 0.009145347489983484 total_time 721.0\n",
      "episode 9399, reward 1573.0, memory_length 2000, epsilon 0.009099734879087034 total_time 721.0\n",
      "episode 9409, reward 2142.0, memory_length 2000, epsilon 0.009054349762036513 total_time 725.0\n",
      "episode 9419, reward 1892.0, memory_length 2000, epsilon 0.009009191004201625 total_time 721.0\n",
      "episode 9429, reward 1652.0, memory_length 2000, epsilon 0.008964257476611073 total_time 724.0\n",
      "episode 9439, reward 1234.0, memory_length 2000, epsilon 0.008919548055924322 total_time 724.0\n",
      "episode 9449, reward 2129.0, memory_length 2000, epsilon 0.00887506162440353 total_time 729.0\n",
      "episode 9459, reward 1616.0, memory_length 2000, epsilon 0.008830797069885592 total_time 725.0\n",
      "episode 9469, reward 1314.0, memory_length 2000, epsilon 0.008786753285754338 total_time 726.0\n",
      "episode 9479, reward 1626.0, memory_length 2000, epsilon 0.008742929170912865 total_time 723.0\n",
      "episode 9489, reward 1468.0, memory_length 2000, epsilon 0.008699323629756034 total_time 723.0\n",
      "episode 9499, reward 1437.0, memory_length 2000, epsilon 0.008655935572143034 total_time 722.0\n",
      "episode 9509, reward 1540.0, memory_length 2000, epsilon 0.008612763913370172 total_time 724.0\n",
      "episode 9519, reward 1992.0, memory_length 2000, epsilon 0.008569807574143724 total_time 724.0\n",
      "episode 9529, reward 1905.0, memory_length 2000, epsilon 0.008527065480552974 total_time 723.0\n",
      "episode 9539, reward 1625.0, memory_length 2000, epsilon 0.008484536564043358 total_time 723.0\n",
      "episode 9549, reward 1410.0, memory_length 2000, epsilon 0.008442219761389744 total_time 723.0\n",
      "episode 9559, reward 1404.0, memory_length 2000, epsilon 0.008400114014669856 total_time 726.0\n",
      "episode 9569, reward 1498.0, memory_length 2000, epsilon 0.00835821827123785 total_time 723.0\n",
      "episode 9579, reward 1881.0, memory_length 2000, epsilon 0.008316531483697952 total_time 731.0\n",
      "episode 9589, reward 1679.0, memory_length 2000, epsilon 0.008275052609878295 total_time 724.0\n",
      "episode 9599, reward 2000.0, memory_length 2000, epsilon 0.00823378061280488 total_time 727.0\n",
      "episode 9609, reward 1800.0, memory_length 2000, epsilon 0.008192714460675628 total_time 725.0\n",
      "episode 9619, reward 1628.0, memory_length 2000, epsilon 0.008151853126834597 total_time 724.0\n",
      "episode 9629, reward 1835.0, memory_length 2000, epsilon 0.00811119558974631 total_time 721.0\n",
      "episode 9639, reward 1962.0, memory_length 2000, epsilon 0.008070740832970229 total_time 730.0\n",
      "episode 9649, reward 1460.0, memory_length 2000, epsilon 0.008030487845135315 total_time 721.0\n",
      "episode 9659, reward 1713.0, memory_length 2000, epsilon 0.007990435619914792 total_time 722.0\n",
      "episode 9669, reward 1910.0, memory_length 2000, epsilon 0.007950583156000935 total_time 725.0\n",
      "episode 9679, reward 1744.0, memory_length 2000, epsilon 0.007910929457080072 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9689, reward 1446.0, memory_length 2000, epsilon 0.007871473531807663 total_time 725.0\n",
      "episode 9699, reward 1581.0, memory_length 2000, epsilon 0.007832214393783524 total_time 726.0\n",
      "episode 9709, reward 1617.0, memory_length 2000, epsilon 0.007793151061527156 total_time 722.0\n",
      "episode 9719, reward 1662.0, memory_length 2000, epsilon 0.00775428255845322 total_time 722.0\n",
      "episode 9729, reward 1571.0, memory_length 2000, epsilon 0.007715607912847108 total_time 721.0\n",
      "episode 9739, reward 1311.0, memory_length 2000, epsilon 0.007677126157840679 total_time 725.0\n",
      "episode 9749, reward 1557.0, memory_length 2000, epsilon 0.007638836331388046 total_time 725.0\n",
      "episode 9759, reward 1720.0, memory_length 2000, epsilon 0.007600737476241555 total_time 724.0\n",
      "episode 9769, reward 1264.0, memory_length 2000, epsilon 0.007562828639927842 total_time 723.0\n",
      "episode 9779, reward 1503.0, memory_length 2000, epsilon 0.007525108874724024 total_time 728.0\n",
      "episode 9789, reward 2044.0, memory_length 2000, epsilon 0.0074875772376340076 total_time 723.0\n",
      "episode 9799, reward 1741.0, memory_length 2000, epsilon 0.007450232790364911 total_time 723.0\n",
      "episode 9809, reward 1517.0, memory_length 2000, epsilon 0.0074130745993036 total_time 723.0\n",
      "episode 9819, reward 1494.0, memory_length 2000, epsilon 0.007376101735493376 total_time 721.0\n",
      "episode 9829, reward 1746.0, memory_length 2000, epsilon 0.007339313274610711 total_time 722.0\n",
      "episode 9839, reward 1882.0, memory_length 2000, epsilon 0.007302708296942168 total_time 722.0\n",
      "episode 9849, reward 1613.0, memory_length 2000, epsilon 0.007266285887361399 total_time 722.0\n",
      "episode 9859, reward 1404.0, memory_length 2000, epsilon 0.007230045135306265 total_time 721.0\n",
      "episode 9869, reward 1391.0, memory_length 2000, epsilon 0.0071939851347560795 total_time 721.0\n",
      "episode 9879, reward 1528.0, memory_length 2000, epsilon 0.007158104984208951 total_time 721.0\n",
      "episode 9889, reward 1935.0, memory_length 2000, epsilon 0.007122403786659245 total_time 722.0\n",
      "episode 9899, reward 2167.0, memory_length 2000, epsilon 0.007086880649575158 total_time 721.0\n",
      "episode 9909, reward 2051.0, memory_length 2000, epsilon 0.0070515346848764255 total_time 722.0\n",
      "episode 9919, reward 1729.0, memory_length 2000, epsilon 0.007016365008912083 total_time 728.0\n",
      "episode 9929, reward 1599.0, memory_length 2000, epsilon 0.006981370742438399 total_time 723.0\n",
      "episode 9939, reward 1430.0, memory_length 2000, epsilon 0.006946551010596889 total_time 724.0\n",
      "episode 9949, reward 1662.0, memory_length 2000, epsilon 0.006911904942892444 total_time 727.0\n",
      "episode 9959, reward 1540.0, memory_length 2000, epsilon 0.006877431673171567 total_time 721.0\n",
      "episode 9969, reward 1545.0, memory_length 2000, epsilon 0.006843130339600718 total_time 723.0\n",
      "episode 9979, reward 2073.0, memory_length 2000, epsilon 0.006809000084644768 total_time 724.0\n",
      "episode 9989, reward 1635.0, memory_length 2000, epsilon 0.006775040055045574 total_time 722.0\n",
      "episode 9999, reward 1660.0, memory_length 2000, epsilon 0.006741249401800625 total_time 721.0\n",
      "Saving Model 10000\n",
      "episode 10009, reward 1755.0, memory_length 2000, epsilon 0.006707627280141827 total_time 731.0\n",
      "episode 10019, reward 1405.0, memory_length 2000, epsilon 0.0066741728495143884 total_time 731.0\n",
      "episode 10029, reward 1850.0, memory_length 2000, epsilon 0.006640885273555802 total_time 734.0\n",
      "episode 10039, reward 1697.0, memory_length 2000, epsilon 0.006607763720074933 total_time 731.0\n",
      "episode 10049, reward 1504.0, memory_length 2000, epsilon 0.006574807361031221 total_time 726.0\n",
      "episode 10059, reward 1195.0, memory_length 2000, epsilon 0.006542015372513967 total_time 721.0\n",
      "episode 10069, reward 1264.0, memory_length 2000, epsilon 0.0065093869347217625 total_time 722.0\n",
      "episode 10079, reward 1685.0, memory_length 2000, epsilon 0.006476921231941956 total_time 726.0\n",
      "episode 10089, reward 1442.0, memory_length 2000, epsilon 0.006444617452530289 total_time 721.0\n",
      "episode 10099, reward 1445.0, memory_length 2000, epsilon 0.006412474788890592 total_time 721.0\n",
      "episode 10109, reward 1512.0, memory_length 2000, epsilon 0.006380492437454601 total_time 722.0\n",
      "episode 10119, reward 1315.0, memory_length 2000, epsilon 0.0063486695986618635 total_time 728.0\n",
      "episode 10129, reward 1517.0, memory_length 2000, epsilon 0.006317005476939753 total_time 726.0\n",
      "episode 10139, reward 2165.0, memory_length 2000, epsilon 0.006285499280683576 total_time 721.0\n",
      "episode 10149, reward 1738.0, memory_length 2000, epsilon 0.006254150222236782 total_time 724.0\n",
      "episode 10159, reward 1132.0, memory_length 2000, epsilon 0.006222957517871287 total_time 721.0\n",
      "episode 10169, reward 1625.0, memory_length 2000, epsilon 0.00619192038776785 total_time 723.0\n",
      "episode 10179, reward 1562.0, memory_length 2000, epsilon 0.006161038055996604 total_time 728.0\n",
      "episode 10189, reward 1946.0, memory_length 2000, epsilon 0.006130309750497645 total_time 723.0\n",
      "episode 10199, reward 1422.0, memory_length 2000, epsilon 0.006099734703061736 total_time 725.0\n",
      "episode 10209, reward 2049.0, memory_length 2000, epsilon 0.0060693121493110985 total_time 725.0\n",
      "episode 10219, reward 1761.0, memory_length 2000, epsilon 0.0060390413286803045 total_time 721.0\n",
      "episode 10229, reward 1690.0, memory_length 2000, epsilon 0.006008921484397255 total_time 726.0\n",
      "episode 10239, reward 1567.0, memory_length 2000, epsilon 0.005978951863464286 total_time 728.0\n",
      "episode 10249, reward 1851.0, memory_length 2000, epsilon 0.0059491317166393085 total_time 723.0\n",
      "episode 10259, reward 1312.0, memory_length 2000, epsilon 0.005919460298417096 total_time 721.0\n",
      "episode 10269, reward 1928.0, memory_length 2000, epsilon 0.005889936867010651 total_time 722.0\n",
      "episode 10279, reward 1662.0, memory_length 2000, epsilon 0.005860560684332649 total_time 725.0\n",
      "episode 10289, reward 1494.0, memory_length 2000, epsilon 0.005831331015976992 total_time 721.0\n",
      "episode 10299, reward 1366.0, memory_length 2000, epsilon 0.005802247131200451 total_time 722.0\n",
      "episode 10309, reward 2000.0, memory_length 2000, epsilon 0.005773308302904384 total_time 727.0\n",
      "episode 10319, reward 1434.0, memory_length 2000, epsilon 0.005744513807616589 total_time 721.0\n",
      "episode 10329, reward 1778.0, memory_length 2000, epsilon 0.0057158629254731785 total_time 729.0\n",
      "episode 10339, reward 1500.0, memory_length 2000, epsilon 0.005687354940200605 total_time 723.0\n",
      "episode 10349, reward 1800.0, memory_length 2000, epsilon 0.005658989139097755 total_time 722.0\n",
      "episode 10359, reward 1436.0, memory_length 2000, epsilon 0.005630764813018121 total_time 724.0\n",
      "episode 10369, reward 1652.0, memory_length 2000, epsilon 0.005602681256352081 total_time 721.0\n",
      "episode 10379, reward 1792.0, memory_length 2000, epsilon 0.005574737767009257 total_time 727.0\n",
      "episode 10389, reward 1554.0, memory_length 2000, epsilon 0.005546933646400958 total_time 728.0\n",
      "episode 10399, reward 1617.0, memory_length 2000, epsilon 0.00551926819942272 total_time 726.0\n",
      "episode 10409, reward 1672.0, memory_length 2000, epsilon 0.0054917407344369324 total_time 723.0\n",
      "episode 10419, reward 1841.0, memory_length 2000, epsilon 0.005464350563255534 total_time 721.0\n",
      "episode 10429, reward 1966.0, memory_length 2000, epsilon 0.00543709700112282 total_time 723.0\n",
      "episode 10439, reward 1295.0, memory_length 2000, epsilon 0.0054099793666983155 total_time 721.0\n",
      "episode 10449, reward 1494.0, memory_length 2000, epsilon 0.00538299698203975 total_time 724.0\n",
      "episode 10459, reward 1761.0, memory_length 2000, epsilon 0.005356149172586098 total_time 723.0\n",
      "episode 10469, reward 1657.0, memory_length 2000, epsilon 0.005329435267140728 total_time 722.0\n",
      "episode 10479, reward 1954.0, memory_length 2000, epsilon 0.005302854597854607 total_time 726.0\n",
      "episode 10489, reward 1415.0, memory_length 2000, epsilon 0.005276406500209628 total_time 725.0\n",
      "episode 10499, reward 1675.0, memory_length 2000, epsilon 0.005250090313001966 total_time 724.0\n",
      "episode 10509, reward 1603.0, memory_length 2000, epsilon 0.005223905378325572 total_time 723.0\n",
      "episode 10519, reward 1333.0, memory_length 2000, epsilon 0.005197851041555715 total_time 723.0\n",
      "episode 10529, reward 1620.0, memory_length 2000, epsilon 0.005171926651332619 total_time 721.0\n",
      "episode 10539, reward 1324.0, memory_length 2000, epsilon 0.005146131559545177 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10549, reward 1623.0, memory_length 2000, epsilon 0.005120465121314752 total_time 723.0\n",
      "episode 10559, reward 1618.0, memory_length 2000, epsilon 0.005094926694979046 total_time 723.0\n",
      "episode 10569, reward 1597.0, memory_length 2000, epsilon 0.00506951564207608 total_time 721.0\n",
      "episode 10579, reward 1761.0, memory_length 2000, epsilon 0.005044231327328204 total_time 722.0\n",
      "episode 10589, reward 1213.0, memory_length 2000, epsilon 0.005019073118626231 total_time 722.0\n",
      "episode 10599, reward 1524.0, memory_length 2000, epsilon 0.004994040387013635 total_time 725.0\n",
      "episode 10609, reward 1387.0, memory_length 2000, epsilon 0.00496913250667082 total_time 723.0\n",
      "episode 10619, reward 1736.0, memory_length 2000, epsilon 0.004944348854899481 total_time 721.0\n",
      "episode 10629, reward 1990.0, memory_length 2000, epsilon 0.004919688812107034 total_time 723.0\n",
      "episode 10639, reward 1932.0, memory_length 2000, epsilon 0.004895151761791122 total_time 724.0\n",
      "episode 10649, reward 1576.0, memory_length 2000, epsilon 0.004870737090524206 total_time 721.0\n",
      "episode 10659, reward 1666.0, memory_length 2000, epsilon 0.004846444187938244 total_time 724.0\n",
      "episode 10669, reward 1553.0, memory_length 2000, epsilon 0.0048222724467093985 total_time 726.0\n",
      "episode 10679, reward 1712.0, memory_length 2000, epsilon 0.004798221262542881 total_time 722.0\n",
      "episode 10689, reward 1462.0, memory_length 2000, epsilon 0.004774290034157834 total_time 722.0\n",
      "episode 10699, reward 2210.0, memory_length 2000, epsilon 0.0047504781632723035 total_time 725.0\n",
      "episode 10709, reward 1724.0, memory_length 2000, epsilon 0.004726785054588276 total_time 725.0\n",
      "episode 10719, reward 1677.0, memory_length 2000, epsilon 0.004703210115776799 total_time 721.0\n",
      "episode 10729, reward 1449.0, memory_length 2000, epsilon 0.004679752757463171 total_time 721.0\n",
      "episode 10739, reward 1872.0, memory_length 2000, epsilon 0.004656412393212222 total_time 726.0\n",
      "episode 10749, reward 1769.0, memory_length 2000, epsilon 0.004633188439513625 total_time 721.0\n",
      "episode 10759, reward 1426.0, memory_length 2000, epsilon 0.004610080315767327 total_time 724.0\n",
      "episode 10769, reward 1419.0, memory_length 2000, epsilon 0.004587087444269032 total_time 723.0\n",
      "episode 10779, reward 1450.0, memory_length 2000, epsilon 0.004564209250195755 total_time 721.0\n",
      "episode 10789, reward 1863.0, memory_length 2000, epsilon 0.004541445161591452 total_time 722.0\n",
      "episode 10799, reward 1772.0, memory_length 2000, epsilon 0.004518794609352723 total_time 724.0\n",
      "episode 10809, reward 1883.0, memory_length 2000, epsilon 0.004496257027214578 total_time 726.0\n",
      "episode 10819, reward 2095.0, memory_length 2000, epsilon 0.004473831851736298 total_time 721.0\n",
      "episode 10829, reward 1539.0, memory_length 2000, epsilon 0.0044515185222873226 total_time 725.0\n",
      "episode 10839, reward 1715.0, memory_length 2000, epsilon 0.004429316481033255 total_time 721.0\n",
      "episode 10849, reward 1750.0, memory_length 2000, epsilon 0.004407225172921907 total_time 723.0\n",
      "episode 10859, reward 1431.0, memory_length 2000, epsilon 0.004385244045669425 total_time 721.0\n",
      "episode 10869, reward 1137.0, memory_length 2000, epsilon 0.004363372549746483 total_time 722.0\n",
      "episode 10879, reward 1698.0, memory_length 2000, epsilon 0.004341610138364544 total_time 724.0\n",
      "episode 10889, reward 1611.0, memory_length 2000, epsilon 0.00431995626746219 total_time 721.0\n",
      "episode 10899, reward 1464.0, memory_length 2000, epsilon 0.004298410395691517 total_time 721.0\n",
      "episode 10909, reward 799.0, memory_length 2000, epsilon 0.004276971984404615 total_time 722.0\n",
      "episode 10919, reward 1600.0, memory_length 2000, epsilon 0.0042556404976400826 total_time 721.0\n",
      "episode 10929, reward 1652.0, memory_length 2000, epsilon 0.004234415402109639 total_time 722.0\n",
      "episode 10939, reward 1490.0, memory_length 2000, epsilon 0.004213296167184791 total_time 722.0\n",
      "episode 10949, reward 1723.0, memory_length 2000, epsilon 0.004192282264883566 total_time 723.0\n",
      "episode 10959, reward 1538.0, memory_length 2000, epsilon 0.00417137316985731 total_time 724.0\n",
      "episode 10969, reward 1360.0, memory_length 2000, epsilon 0.004150568359377561 total_time 730.0\n",
      "episode 10979, reward 1810.0, memory_length 2000, epsilon 0.004129867313322968 total_time 729.0\n",
      "episode 10989, reward 1548.0, memory_length 2000, epsilon 0.004109269514166309 total_time 728.0\n",
      "episode 10999, reward 1611.0, memory_length 2000, epsilon 0.004088774446961528 total_time 729.0\n",
      "Saving Model 11000\n",
      "episode 11009, reward 1681.0, memory_length 2000, epsilon 0.0040683815993308795 total_time 721.0\n",
      "episode 11019, reward 1426.0, memory_length 2000, epsilon 0.004048090461452108 total_time 726.0\n",
      "episode 11029, reward 1873.0, memory_length 2000, epsilon 0.004027900526045712 total_time 725.0\n",
      "episode 11039, reward 963.0, memory_length 2000, epsilon 0.004007811288362254 total_time 730.0\n",
      "episode 11049, reward 1594.0, memory_length 2000, epsilon 0.0039878222461697446 total_time 723.0\n",
      "episode 11059, reward 1521.0, memory_length 2000, epsilon 0.003967932899741086 total_time 724.0\n",
      "episode 11069, reward 2120.0, memory_length 2000, epsilon 0.003948142751841587 total_time 721.0\n",
      "episode 11079, reward 1368.0, memory_length 2000, epsilon 0.003928451307716517 total_time 724.0\n",
      "episode 11089, reward 2074.0, memory_length 2000, epsilon 0.003908858075078747 total_time 722.0\n",
      "episode 11099, reward 1658.0, memory_length 2000, epsilon 0.0038893625640964405 total_time 722.0\n",
      "episode 11109, reward 1710.0, memory_length 2000, epsilon 0.0038699642873808076 total_time 726.0\n",
      "episode 11119, reward 1687.0, memory_length 2000, epsilon 0.0038506627599739197 total_time 722.0\n",
      "episode 11129, reward 1589.0, memory_length 2000, epsilon 0.0038314574993365868 total_time 731.0\n",
      "episode 11139, reward 1592.0, memory_length 2000, epsilon 0.0038123480253362927 total_time 725.0\n",
      "episode 11149, reward 1485.0, memory_length 2000, epsilon 0.0037933338602351885 total_time 727.0\n",
      "episode 11159, reward 1522.0, memory_length 2000, epsilon 0.003774414528678163 total_time 723.0\n",
      "episode 11169, reward 1821.0, memory_length 2000, epsilon 0.003755589557680939 total_time 723.0\n",
      "episode 11179, reward 1823.0, memory_length 2000, epsilon 0.003736858476618261 total_time 730.0\n",
      "episode 11189, reward 1634.0, memory_length 2000, epsilon 0.0037182208172121265 total_time 725.0\n",
      "episode 11199, reward 1891.0, memory_length 2000, epsilon 0.003699676113520079 total_time 724.0\n",
      "episode 11209, reward 1344.0, memory_length 2000, epsilon 0.003681223901923562 total_time 724.0\n",
      "episode 11219, reward 1855.0, memory_length 2000, epsilon 0.0036628637211163235 total_time 728.0\n",
      "episode 11229, reward 1263.0, memory_length 2000, epsilon 0.0036445951120928836 total_time 721.0\n",
      "episode 11239, reward 1638.0, memory_length 2000, epsilon 0.0036264176181370726 total_time 725.0\n",
      "episode 11249, reward 1288.0, memory_length 2000, epsilon 0.003608330784810591 total_time 731.0\n",
      "episode 11259, reward 1338.0, memory_length 2000, epsilon 0.0035903341599416634 total_time 723.0\n",
      "episode 11269, reward 2034.0, memory_length 2000, epsilon 0.0035724272936137314 total_time 726.0\n",
      "episode 11279, reward 1941.0, memory_length 2000, epsilon 0.003554609738154204 total_time 723.0\n",
      "episode 11289, reward 1541.0, memory_length 2000, epsilon 0.003536881048123266 total_time 725.0\n",
      "episode 11299, reward 1717.0, memory_length 2000, epsilon 0.003519240780302744 total_time 721.0\n",
      "episode 11309, reward 1512.0, memory_length 2000, epsilon 0.00350168849368502 total_time 724.0\n",
      "episode 11319, reward 1520.0, memory_length 2000, epsilon 0.003484223749462022 total_time 721.0\n",
      "episode 11329, reward 1915.0, memory_length 2000, epsilon 0.00346684611101423 total_time 726.0\n",
      "episode 11339, reward 1729.0, memory_length 2000, epsilon 0.0034495551438997784 total_time 722.0\n",
      "episode 11349, reward 1820.0, memory_length 2000, epsilon 0.003432350415843589 total_time 726.0\n",
      "episode 11359, reward 2026.0, memory_length 2000, epsilon 0.003415231496726564 total_time 726.0\n",
      "episode 11369, reward 1384.0, memory_length 2000, epsilon 0.0033981979585748336 total_time 723.0\n",
      "episode 11379, reward 1791.0, memory_length 2000, epsilon 0.0033812493755490574 total_time 729.0\n",
      "episode 11389, reward 1639.0, memory_length 2000, epsilon 0.003364385323933774 total_time 726.0\n",
      "episode 11399, reward 1657.0, memory_length 2000, epsilon 0.0033476053821268207 total_time 724.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11409, reward 1805.0, memory_length 2000, epsilon 0.0033309091306287742 total_time 721.0\n",
      "episode 11419, reward 1655.0, memory_length 2000, epsilon 0.0033142961520324795 total_time 721.0\n",
      "episode 11429, reward 1711.0, memory_length 2000, epsilon 0.0032977660310126045 total_time 723.0\n",
      "episode 11439, reward 1770.0, memory_length 2000, epsilon 0.0032813183543152643 total_time 723.0\n",
      "episode 11449, reward 1782.0, memory_length 2000, epsilon 0.003264952710747684 total_time 729.0\n",
      "episode 11459, reward 1538.0, memory_length 2000, epsilon 0.003248668691167922 total_time 721.0\n",
      "episode 11469, reward 1306.0, memory_length 2000, epsilon 0.0032324658884746406 total_time 737.0\n",
      "episode 11479, reward 1890.0, memory_length 2000, epsilon 0.0032163438975969265 total_time 721.0\n",
      "episode 11489, reward 1485.0, memory_length 2000, epsilon 0.0032003023154841726 total_time 724.0\n",
      "episode 11499, reward 1832.0, memory_length 2000, epsilon 0.0031843407410959887 total_time 730.0\n",
      "episode 11509, reward 1838.0, memory_length 2000, epsilon 0.0031684587753921835 total_time 724.0\n",
      "episode 11519, reward 1116.0, memory_length 2000, epsilon 0.003152656021322787 total_time 723.0\n",
      "episode 11529, reward 1305.0, memory_length 2000, epsilon 0.003136932083818124 total_time 722.0\n",
      "episode 11539, reward 1566.0, memory_length 2000, epsilon 0.0031212865697789398 total_time 726.0\n",
      "episode 11549, reward 1717.0, memory_length 2000, epsilon 0.003105719088066566 total_time 725.0\n",
      "episode 11559, reward 1593.0, memory_length 2000, epsilon 0.0030902292494931483 total_time 730.0\n",
      "episode 11569, reward 1536.0, memory_length 2000, epsilon 0.0030748166668119197 total_time 723.0\n",
      "episode 11579, reward 1730.0, memory_length 2000, epsilon 0.003059480954707508 total_time 726.0\n",
      "episode 11589, reward 1595.0, memory_length 2000, epsilon 0.0030442217297863123 total_time 726.0\n",
      "episode 11599, reward 1558.0, memory_length 2000, epsilon 0.0030290386105669147 total_time 724.0\n",
      "episode 11609, reward 1397.0, memory_length 2000, epsilon 0.0030139312174705443 total_time 724.0\n",
      "episode 11619, reward 1591.0, memory_length 2000, epsilon 0.002998899172811586 total_time 722.0\n",
      "episode 11629, reward 1302.0, memory_length 2000, epsilon 0.0029839421007881407 total_time 725.0\n",
      "episode 11639, reward 1504.0, memory_length 2000, epsilon 0.002969059627472626 total_time 722.0\n",
      "episode 11649, reward 1566.0, memory_length 2000, epsilon 0.00295425138080244 total_time 727.0\n",
      "episode 11659, reward 1631.0, memory_length 2000, epsilon 0.002939516990570641 total_time 722.0\n",
      "episode 11669, reward 1800.0, memory_length 2000, epsilon 0.0029248560884167062 total_time 729.0\n",
      "episode 11679, reward 1504.0, memory_length 2000, epsilon 0.0029102683078173187 total_time 722.0\n",
      "episode 11689, reward 1536.0, memory_length 2000, epsilon 0.0028957532840772028 total_time 728.0\n",
      "episode 11699, reward 1809.0, memory_length 2000, epsilon 0.0028813106543200094 total_time 721.0\n",
      "episode 11709, reward 1598.0, memory_length 2000, epsilon 0.002866940057479243 total_time 731.0\n",
      "episode 11719, reward 1692.0, memory_length 2000, epsilon 0.0028526411342892325 total_time 725.0\n",
      "episode 11729, reward 1837.0, memory_length 2000, epsilon 0.0028384135272761526 total_time 726.0\n",
      "episode 11739, reward 1577.0, memory_length 2000, epsilon 0.0028242568807490907 total_time 723.0\n",
      "episode 11749, reward 1545.0, memory_length 2000, epsilon 0.002810170840791145 total_time 726.0\n",
      "episode 11759, reward 1816.0, memory_length 2000, epsilon 0.002796155055250582 total_time 726.0\n",
      "episode 11769, reward 1937.0, memory_length 2000, epsilon 0.0027822091737320334 total_time 723.0\n",
      "episode 11779, reward 1364.0, memory_length 2000, epsilon 0.0027683328475877353 total_time 728.0\n",
      "episode 11789, reward 1405.0, memory_length 2000, epsilon 0.0027545257299088103 total_time 727.0\n",
      "episode 11799, reward 2035.0, memory_length 2000, epsilon 0.002740787475516599 total_time 726.0\n",
      "episode 11809, reward 1650.0, memory_length 2000, epsilon 0.002727117740954022 total_time 726.0\n",
      "episode 11819, reward 1390.0, memory_length 2000, epsilon 0.0027135161844770088 total_time 723.0\n",
      "episode 11829, reward 1333.0, memory_length 2000, epsilon 0.0026999824660459367 total_time 723.0\n",
      "episode 11839, reward 1665.0, memory_length 2000, epsilon 0.0026865162473171398 total_time 726.0\n",
      "episode 11849, reward 1571.0, memory_length 2000, epsilon 0.0026731171916344492 total_time 721.0\n",
      "episode 11859, reward 1630.0, memory_length 2000, epsilon 0.0026597849640207735 total_time 726.0\n",
      "episode 11869, reward 1526.0, memory_length 2000, epsilon 0.00264651923116973 total_time 725.0\n",
      "episode 11879, reward 1865.0, memory_length 2000, epsilon 0.002633319661437305 total_time 724.0\n",
      "episode 11889, reward 1602.0, memory_length 2000, epsilon 0.0026201859248335653 total_time 726.0\n",
      "episode 11899, reward 1629.0, memory_length 2000, epsilon 0.0026071176930144175 total_time 722.0\n",
      "episode 11909, reward 1710.0, memory_length 2000, epsilon 0.0025941146392733823 total_time 722.0\n",
      "episode 11919, reward 1620.0, memory_length 2000, epsilon 0.002581176438533439 total_time 731.0\n",
      "episode 11929, reward 1305.0, memory_length 2000, epsilon 0.0025683027673388957 total_time 721.0\n",
      "episode 11939, reward 1926.0, memory_length 2000, epsilon 0.0025554933038473013 total_time 730.0\n",
      "episode 11949, reward 1580.0, memory_length 2000, epsilon 0.0025427477278214023 total_time 722.0\n",
      "episode 11959, reward 1263.0, memory_length 2000, epsilon 0.0025300657206211337 total_time 721.0\n",
      "episode 11969, reward 1945.0, memory_length 2000, epsilon 0.0025174469651956547 total_time 723.0\n",
      "episode 11979, reward 1311.0, memory_length 2000, epsilon 0.002504891146075421 total_time 721.0\n",
      "episode 11989, reward 1655.0, memory_length 2000, epsilon 0.0024923979493643037 total_time 724.0\n",
      "episode 11999, reward 1715.0, memory_length 2000, epsilon 0.0024799670627317335 total_time 724.0\n",
      "Saving Model 12000\n",
      "episode 12009, reward 1503.0, memory_length 2000, epsilon 0.002467598175404897 total_time 721.0\n",
      "episode 12019, reward 1684.0, memory_length 2000, epsilon 0.002455290978160966 total_time 721.0\n",
      "episode 12029, reward 1539.0, memory_length 2000, epsilon 0.002443045163319369 total_time 727.0\n",
      "episode 12039, reward 2044.0, memory_length 2000, epsilon 0.0024308604247340973 total_time 726.0\n",
      "episode 12049, reward 1809.0, memory_length 2000, epsilon 0.002418736457786051 total_time 725.0\n",
      "episode 12059, reward 1729.0, memory_length 2000, epsilon 0.002406672959375423 total_time 729.0\n",
      "episode 12069, reward 1398.0, memory_length 2000, epsilon 0.00239466962791413 total_time 721.0\n",
      "episode 12079, reward 1568.0, memory_length 2000, epsilon 0.002382726163318257 total_time 721.0\n",
      "episode 12089, reward 1316.0, memory_length 2000, epsilon 0.0023708422670005672 total_time 722.0\n",
      "episode 12099, reward 1558.0, memory_length 2000, epsilon 0.0023590176418630334 total_time 722.0\n",
      "episode 12109, reward 1695.0, memory_length 2000, epsilon 0.002347251992289413 total_time 723.0\n",
      "episode 12119, reward 1707.0, memory_length 2000, epsilon 0.0023355450241378515 total_time 728.0\n",
      "episode 12129, reward 1598.0, memory_length 2000, epsilon 0.002323896444733537 total_time 726.0\n",
      "episode 12139, reward 1394.0, memory_length 2000, epsilon 0.002312305962861375 total_time 726.0\n",
      "episode 12149, reward 1541.0, memory_length 2000, epsilon 0.002300773288758719 total_time 725.0\n",
      "episode 12159, reward 1704.0, memory_length 2000, epsilon 0.0022892981341081143 total_time 723.0\n",
      "episode 12169, reward 1413.0, memory_length 2000, epsilon 0.002277880212030097 total_time 721.0\n",
      "episode 12179, reward 1747.0, memory_length 2000, epsilon 0.00226651923707602 total_time 726.0\n",
      "episode 12189, reward 1374.0, memory_length 2000, epsilon 0.002255214925220918 total_time 724.0\n",
      "episode 12199, reward 1523.0, memory_length 2000, epsilon 0.0022439669938564056 total_time 724.0\n",
      "episode 12209, reward 2043.0, memory_length 2000, epsilon 0.0022327751617836128 total_time 728.0\n",
      "episode 12219, reward 1630.0, memory_length 2000, epsilon 0.002221639149206155 total_time 723.0\n",
      "episode 12229, reward 1425.0, memory_length 2000, epsilon 0.002210558677723136 total_time 721.0\n",
      "episode 12239, reward 1983.0, memory_length 2000, epsilon 0.0021995334703221957 total_time 723.0\n",
      "episode 12249, reward 1635.0, memory_length 2000, epsilon 0.002188563251372572 total_time 723.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12259, reward 1602.0, memory_length 2000, epsilon 0.002177647746618221 total_time 725.0\n",
      "episode 12269, reward 1621.0, memory_length 2000, epsilon 0.0021667866831709542 total_time 726.0\n",
      "episode 12279, reward 1748.0, memory_length 2000, epsilon 0.00215597978950362 total_time 722.0\n",
      "episode 12289, reward 1535.0, memory_length 2000, epsilon 0.0021452267954433146 total_time 730.0\n",
      "episode 12299, reward 1431.0, memory_length 2000, epsilon 0.002134527432164626 total_time 723.0\n",
      "episode 12309, reward 1802.0, memory_length 2000, epsilon 0.002123881432182913 total_time 724.0\n",
      "episode 12319, reward 1600.0, memory_length 2000, epsilon 0.0021132885293476253 total_time 722.0\n",
      "episode 12329, reward 1723.0, memory_length 2000, epsilon 0.002102748458835638 total_time 721.0\n",
      "episode 12339, reward 1639.0, memory_length 2000, epsilon 0.0020922609571446408 total_time 723.0\n",
      "episode 12349, reward 1620.0, memory_length 2000, epsilon 0.0020818257620865434 total_time 727.0\n",
      "episode 12359, reward 1645.0, memory_length 2000, epsilon 0.0020714426127809273 total_time 725.0\n",
      "episode 12369, reward 1765.0, memory_length 2000, epsilon 0.0020611112496485176 total_time 724.0\n",
      "episode 12379, reward 1372.0, memory_length 2000, epsilon 0.0020508314144046997 total_time 721.0\n",
      "episode 12389, reward 1568.0, memory_length 2000, epsilon 0.002040602850053054 total_time 725.0\n",
      "episode 12399, reward 1551.0, memory_length 2000, epsilon 0.0020304253008789426 total_time 722.0\n",
      "episode 12409, reward 1350.0, memory_length 2000, epsilon 0.0020202985124431047 total_time 727.0\n",
      "episode 12419, reward 1665.0, memory_length 2000, epsilon 0.0020102222315753018 total_time 721.0\n",
      "episode 12429, reward 1457.0, memory_length 2000, epsilon 0.002000196206367988 total_time 724.0\n",
      "episode 12439, reward 997.0, memory_length 2000, epsilon 0.00199022018617001 total_time 725.0\n",
      "episode 12449, reward 1462.0, memory_length 2000, epsilon 0.0019802939215803434 total_time 724.0\n",
      "episode 12459, reward 1436.0, memory_length 2000, epsilon 0.001970417164441857 total_time 725.0\n",
      "episode 12469, reward 1628.0, memory_length 2000, epsilon 0.0019605896678351075 total_time 721.0\n",
      "episode 12479, reward 1639.0, memory_length 2000, epsilon 0.0019508111860721666 total_time 725.0\n",
      "episode 12489, reward 1788.0, memory_length 2000, epsilon 0.0019410814746904836 total_time 725.0\n",
      "episode 12499, reward 1798.0, memory_length 2000, epsilon 0.001931400290446766 total_time 725.0\n",
      "episode 12509, reward 789.0, memory_length 2000, epsilon 0.0019217673913109036 total_time 728.0\n",
      "episode 12519, reward 1396.0, memory_length 2000, epsilon 0.0019121825364599159 total_time 721.0\n",
      "episode 12529, reward 1782.0, memory_length 2000, epsilon 0.001902645486271933 total_time 731.0\n",
      "episode 12539, reward 1485.0, memory_length 2000, epsilon 0.0018931560023202028 total_time 721.0\n",
      "episode 12549, reward 1550.0, memory_length 2000, epsilon 0.0018837138473671326 total_time 723.0\n",
      "episode 12559, reward 1742.0, memory_length 2000, epsilon 0.0018743187853583552 total_time 725.0\n",
      "episode 12569, reward 1346.0, memory_length 2000, epsilon 0.001864970581416834 total_time 721.0\n",
      "episode 12579, reward 1580.0, memory_length 2000, epsilon 0.0018556690018369825 total_time 721.0\n",
      "episode 12589, reward 1350.0, memory_length 2000, epsilon 0.0018464138140788264 total_time 731.0\n",
      "episode 12599, reward 1711.0, memory_length 2000, epsilon 0.0018372047867621895 total_time 725.0\n",
      "episode 12609, reward 1792.0, memory_length 2000, epsilon 0.0018280416896609096 total_time 726.0\n",
      "episode 12619, reward 1590.0, memory_length 2000, epsilon 0.0018189242936970818 total_time 724.0\n",
      "episode 12629, reward 1879.0, memory_length 2000, epsilon 0.0018098523709353322 total_time 724.0\n",
      "episode 12639, reward 1841.0, memory_length 2000, epsilon 0.0018008256945771176 total_time 722.0\n",
      "episode 12649, reward 1822.0, memory_length 2000, epsilon 0.001791844038955062 total_time 722.0\n",
      "episode 12659, reward 1371.0, memory_length 2000, epsilon 0.0017829071795273058 total_time 721.0\n",
      "episode 12669, reward 1145.0, memory_length 2000, epsilon 0.0017740148928718975 total_time 725.0\n",
      "episode 12679, reward 1702.0, memory_length 2000, epsilon 0.0017651669566812074 total_time 722.0\n",
      "episode 12689, reward 1742.0, memory_length 2000, epsilon 0.0017563631497563707 total_time 723.0\n",
      "episode 12699, reward 1887.0, memory_length 2000, epsilon 0.0017476032520017547 total_time 725.0\n",
      "episode 12709, reward 1409.0, memory_length 2000, epsilon 0.0017388870444194602 total_time 721.0\n",
      "episode 12719, reward 1533.0, memory_length 2000, epsilon 0.001730214309103843 total_time 721.0\n",
      "episode 12729, reward 1704.0, memory_length 2000, epsilon 0.0017215848292360676 total_time 722.0\n",
      "episode 12739, reward 2025.0, memory_length 2000, epsilon 0.0017129983890786904 total_time 727.0\n",
      "episode 12749, reward 1525.0, memory_length 2000, epsilon 0.001704454773970259 total_time 724.0\n",
      "episode 12759, reward 1728.0, memory_length 2000, epsilon 0.0016959537703199504 total_time 724.0\n",
      "episode 12769, reward 1530.0, memory_length 2000, epsilon 0.0016874951656022312 total_time 726.0\n",
      "episode 12779, reward 1594.0, memory_length 2000, epsilon 0.001679078748351542 total_time 721.0\n",
      "episode 12789, reward 1521.0, memory_length 2000, epsilon 0.001670704308157014 total_time 722.0\n",
      "episode 12799, reward 1425.0, memory_length 2000, epsilon 0.0016623716356572059 total_time 721.0\n",
      "episode 12809, reward 1530.0, memory_length 2000, epsilon 0.0016540805225348694 total_time 721.0\n",
      "episode 12819, reward 1353.0, memory_length 2000, epsilon 0.0016458307615117482 total_time 722.0\n",
      "episode 12829, reward 1644.0, memory_length 2000, epsilon 0.001637622146343385 total_time 721.0\n",
      "episode 12839, reward 1339.0, memory_length 2000, epsilon 0.001629454471813973 total_time 724.0\n",
      "episode 12849, reward 1566.0, memory_length 2000, epsilon 0.0016213275337312245 total_time 730.0\n",
      "episode 12859, reward 1289.0, memory_length 2000, epsilon 0.001613241128921263 total_time 724.0\n",
      "episode 12869, reward 1703.0, memory_length 2000, epsilon 0.0016051950552235475 total_time 725.0\n",
      "episode 12879, reward 1836.0, memory_length 2000, epsilon 0.0015971891114858168 total_time 730.0\n",
      "episode 12889, reward 1682.0, memory_length 2000, epsilon 0.0015892230975590588 total_time 726.0\n",
      "episode 12899, reward 1459.0, memory_length 2000, epsilon 0.0015812968142925135 total_time 724.0\n",
      "episode 12909, reward 1766.0, memory_length 2000, epsilon 0.0015734100635286844 total_time 723.0\n",
      "episode 12919, reward 1386.0, memory_length 2000, epsilon 0.0015655626480983924 total_time 723.0\n",
      "episode 12929, reward 1662.0, memory_length 2000, epsilon 0.0015577543718158424 total_time 725.0\n",
      "episode 12939, reward 1643.0, memory_length 2000, epsilon 0.001549985039473721 total_time 722.0\n",
      "episode 12949, reward 1860.0, memory_length 2000, epsilon 0.0015422544568383146 total_time 722.0\n",
      "episode 12959, reward 1612.0, memory_length 2000, epsilon 0.0015345624306446553 total_time 724.0\n",
      "episode 12969, reward 1767.0, memory_length 2000, epsilon 0.0015269087685916875 total_time 722.0\n",
      "episode 12979, reward 1757.0, memory_length 2000, epsilon 0.0015192932793374593 total_time 722.0\n",
      "episode 12989, reward 1319.0, memory_length 2000, epsilon 0.001511715772494346 total_time 727.0\n",
      "episode 12999, reward 1580.0, memory_length 2000, epsilon 0.0015041760586242804 total_time 724.0\n",
      "Saving Model 13000\n",
      "episode 13009, reward 1864.0, memory_length 2000, epsilon 0.0014966739492340226 total_time 721.0\n",
      "episode 13019, reward 1647.0, memory_length 2000, epsilon 0.0014892092567704478 total_time 721.0\n",
      "episode 13029, reward 1783.0, memory_length 2000, epsilon 0.0014817817946158553 total_time 721.0\n",
      "episode 13039, reward 1809.0, memory_length 2000, epsilon 0.0014743913770833043 total_time 723.0\n",
      "episode 13049, reward 1414.0, memory_length 2000, epsilon 0.0014670378194119717 total_time 729.0\n",
      "episode 13059, reward 1603.0, memory_length 2000, epsilon 0.0014597209377625313 total_time 724.0\n",
      "episode 13069, reward 1771.0, memory_length 2000, epsilon 0.0014524405492125636 total_time 723.0\n",
      "episode 13079, reward 1565.0, memory_length 2000, epsilon 0.0014451964717519742 total_time 722.0\n",
      "episode 13089, reward 1392.0, memory_length 2000, epsilon 0.0014379885242784493 total_time 723.0\n",
      "episode 13099, reward 1889.0, memory_length 2000, epsilon 0.0014308165265929267 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13109, reward 1712.0, memory_length 2000, epsilon 0.0014236802993950906 total_time 722.0\n",
      "episode 13119, reward 1352.0, memory_length 2000, epsilon 0.0014165796642788893 total_time 721.0\n",
      "episode 13129, reward 1847.0, memory_length 2000, epsilon 0.0014095144437280755 total_time 724.0\n",
      "episode 13139, reward 1671.0, memory_length 2000, epsilon 0.0014024844611117656 total_time 724.0\n",
      "episode 13149, reward 1728.0, memory_length 2000, epsilon 0.0013954895406800313 total_time 723.0\n",
      "episode 13159, reward 1719.0, memory_length 2000, epsilon 0.0013885295075594956 total_time 731.0\n",
      "episode 13169, reward 1671.0, memory_length 2000, epsilon 0.001381604187748968 total_time 723.0\n",
      "episode 13179, reward 1863.0, memory_length 2000, epsilon 0.001374713408115093 total_time 731.0\n",
      "episode 13189, reward 1412.0, memory_length 2000, epsilon 0.0013678569963880207 total_time 726.0\n",
      "episode 13199, reward 1732.0, memory_length 2000, epsilon 0.0013610347811571003 total_time 723.0\n",
      "episode 13209, reward 1821.0, memory_length 2000, epsilon 0.0013542465918665965 total_time 725.0\n",
      "episode 13219, reward 1917.0, memory_length 2000, epsilon 0.0013474922588114229 total_time 722.0\n",
      "episode 13229, reward 1656.0, memory_length 2000, epsilon 0.0013407716131329003 total_time 721.0\n",
      "episode 13239, reward 1554.0, memory_length 2000, epsilon 0.0013340844868145393 total_time 728.0\n",
      "episode 13249, reward 1788.0, memory_length 2000, epsilon 0.001327430712677832 total_time 723.0\n",
      "episode 13259, reward 1346.0, memory_length 2000, epsilon 0.001320810124378079 total_time 728.0\n",
      "episode 13269, reward 1654.0, memory_length 2000, epsilon 0.0013142225564002276 total_time 725.0\n",
      "episode 13279, reward 1890.0, memory_length 2000, epsilon 0.0013076678440547354 total_time 722.0\n",
      "episode 13289, reward 1495.0, memory_length 2000, epsilon 0.0013011458234734523 total_time 725.0\n",
      "episode 13299, reward 1711.0, memory_length 2000, epsilon 0.001294656331605524 total_time 721.0\n",
      "episode 13309, reward 1350.0, memory_length 2000, epsilon 0.001288199206213315 total_time 721.0\n",
      "episode 13319, reward 1510.0, memory_length 2000, epsilon 0.001281774285868356 total_time 729.0\n",
      "episode 13329, reward 1763.0, memory_length 2000, epsilon 0.0012753814099473028 total_time 726.0\n",
      "episode 13339, reward 1283.0, memory_length 2000, epsilon 0.0012690204186279247 total_time 724.0\n",
      "episode 13349, reward 1328.0, memory_length 2000, epsilon 0.001262691152885107 total_time 722.0\n",
      "episode 13359, reward 1878.0, memory_length 2000, epsilon 0.0012563934544868767 total_time 725.0\n",
      "episode 13369, reward 1656.0, memory_length 2000, epsilon 0.001250127165990446 total_time 728.0\n",
      "episode 13379, reward 1443.0, memory_length 2000, epsilon 0.0012438921307382756 total_time 723.0\n",
      "episode 13389, reward 1510.0, memory_length 2000, epsilon 0.0012376881928541587 total_time 722.0\n",
      "episode 13399, reward 1724.0, memory_length 2000, epsilon 0.0012315151972393274 total_time 728.0\n",
      "episode 13409, reward 1550.0, memory_length 2000, epsilon 0.0012253729895685685 total_time 725.0\n",
      "episode 13419, reward 1889.0, memory_length 2000, epsilon 0.0012192614162863703 total_time 721.0\n",
      "episode 13429, reward 1626.0, memory_length 2000, epsilon 0.0012131803246030824 total_time 724.0\n",
      "episode 13439, reward 1629.0, memory_length 2000, epsilon 0.0012071295624910964 total_time 721.0\n",
      "episode 13449, reward 1545.0, memory_length 2000, epsilon 0.0012011089786810438 total_time 723.0\n",
      "episode 13459, reward 1531.0, memory_length 2000, epsilon 0.001195118422658016 total_time 727.0\n",
      "episode 13469, reward 1545.0, memory_length 2000, epsilon 0.0011891577446578006 total_time 725.0\n",
      "episode 13479, reward 1364.0, memory_length 2000, epsilon 0.001183226795663136 total_time 733.0\n",
      "episode 13489, reward 1611.0, memory_length 2000, epsilon 0.0011773254273999905 total_time 723.0\n",
      "episode 13499, reward 1779.0, memory_length 2000, epsilon 0.0011714534923338489 total_time 721.0\n",
      "episode 13509, reward 1564.0, memory_length 2000, epsilon 0.0011656108436660288 total_time 726.0\n",
      "episode 13519, reward 1901.0, memory_length 2000, epsilon 0.0011597973353300096 total_time 722.0\n",
      "episode 13529, reward 1623.0, memory_length 2000, epsilon 0.0011540128219877798 total_time 721.0\n",
      "episode 13539, reward 1894.0, memory_length 2000, epsilon 0.0011482571590262043 total_time 723.0\n",
      "episode 13549, reward 1555.0, memory_length 2000, epsilon 0.0011425302025534097 total_time 721.0\n",
      "episode 13559, reward 1675.0, memory_length 2000, epsilon 0.0011368318093951848 total_time 723.0\n",
      "episode 13569, reward 1792.0, memory_length 2000, epsilon 0.001131161837091406 total_time 730.0\n",
      "episode 13579, reward 1863.0, memory_length 2000, epsilon 0.001125520143892469 total_time 725.0\n",
      "episode 13589, reward 1931.0, memory_length 2000, epsilon 0.00111990658875575 total_time 730.0\n",
      "episode 13599, reward 1720.0, memory_length 2000, epsilon 0.0011143210313420788 total_time 726.0\n",
      "episode 13609, reward 1751.0, memory_length 2000, epsilon 0.0011087633320122285 total_time 721.0\n",
      "episode 13619, reward 1691.0, memory_length 2000, epsilon 0.0011032333518234269 total_time 723.0\n",
      "episode 13629, reward 1657.0, memory_length 2000, epsilon 0.001097730952525881 total_time 724.0\n",
      "episode 13639, reward 1692.0, memory_length 2000, epsilon 0.0010922559965593204 total_time 724.0\n",
      "episode 13649, reward 1600.0, memory_length 2000, epsilon 0.0010868083470495634 total_time 726.0\n",
      "episode 13659, reward 1818.0, memory_length 2000, epsilon 0.0010813878678050874 total_time 722.0\n",
      "episode 13669, reward 1483.0, memory_length 2000, epsilon 0.0010759944233136285 total_time 725.0\n",
      "episode 13679, reward 1431.0, memory_length 2000, epsilon 0.0010706278787387942 total_time 728.0\n",
      "episode 13689, reward 1647.0, memory_length 2000, epsilon 0.0010652880999166901 total_time 727.0\n",
      "episode 13699, reward 1421.0, memory_length 2000, epsilon 0.001059974953352568 total_time 724.0\n",
      "episode 13709, reward 1621.0, memory_length 2000, epsilon 0.0010546883062174865 total_time 727.0\n",
      "episode 13719, reward 1443.0, memory_length 2000, epsilon 0.0010494280263449924 total_time 721.0\n",
      "episode 13729, reward 1368.0, memory_length 2000, epsilon 0.0010441939822278133 total_time 721.0\n",
      "episode 13739, reward 1666.0, memory_length 2000, epsilon 0.0010389860430145765 total_time 729.0\n",
      "episode 13749, reward 1980.0, memory_length 2000, epsilon 0.0010338040785065287 total_time 726.0\n",
      "episode 13759, reward 1856.0, memory_length 2000, epsilon 0.0010286479591542876 total_time 725.0\n",
      "episode 13769, reward 1734.0, memory_length 2000, epsilon 0.0010235175560546008 total_time 728.0\n",
      "episode 13779, reward 1738.0, memory_length 2000, epsilon 0.0010184127409471235 total_time 728.0\n",
      "episode 13789, reward 1415.0, memory_length 2000, epsilon 0.0010133333862112125 total_time 726.0\n",
      "episode 13799, reward 1729.0, memory_length 2000, epsilon 0.0010082793648627346 total_time 721.0\n",
      "episode 13809, reward 1943.0, memory_length 2000, epsilon 0.0010032505505508918 total_time 724.0\n",
      "episode 13819, reward 2019.0, memory_length 2000, epsilon 0.0009982468175550663 total_time 722.0\n",
      "episode 13829, reward 1361.0, memory_length 2000, epsilon 0.000993268040781672 total_time 723.0\n",
      "episode 13839, reward 1465.0, memory_length 2000, epsilon 0.0009883140957610299 total_time 723.0\n",
      "episode 13849, reward 1352.0, memory_length 2000, epsilon 0.0009833848586442563 total_time 726.0\n",
      "episode 13859, reward 1769.0, memory_length 2000, epsilon 0.000978480206200167 total_time 724.0\n",
      "episode 13869, reward 1719.0, memory_length 2000, epsilon 0.0009736000158121954 total_time 726.0\n",
      "episode 13879, reward 1799.0, memory_length 2000, epsilon 0.0009687441654753273 total_time 723.0\n",
      "episode 13889, reward 1716.0, memory_length 2000, epsilon 0.0009639125337930508 total_time 721.0\n",
      "episode 13899, reward 1477.0, memory_length 2000, epsilon 0.0009591049999743237 total_time 723.0\n",
      "episode 13909, reward 1517.0, memory_length 2000, epsilon 0.0009543214438305494 total_time 722.0\n",
      "episode 13919, reward 1881.0, memory_length 2000, epsilon 0.0009495617457725752 total_time 726.0\n",
      "episode 13929, reward 1917.0, memory_length 2000, epsilon 0.0009448257868077017 total_time 721.0\n",
      "episode 13939, reward 1326.0, memory_length 2000, epsilon 0.0009401134485367081 total_time 723.0\n",
      "episode 13949, reward 1818.0, memory_length 2000, epsilon 0.0009354246131508923 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13959, reward 1670.0, memory_length 2000, epsilon 0.0009307591634291251 total_time 723.0\n",
      "episode 13969, reward 1707.0, memory_length 2000, epsilon 0.0009261169827349209 total_time 730.0\n",
      "episode 13979, reward 1637.0, memory_length 2000, epsilon 0.0009214979550135194 total_time 721.0\n",
      "episode 13989, reward 1644.0, memory_length 2000, epsilon 0.0009169019647889888 total_time 728.0\n",
      "episode 13999, reward 1654.0, memory_length 2000, epsilon 0.0009123288971613334 total_time 726.0\n",
      "Saving Model 14000\n",
      "episode 14009, reward 1783.0, memory_length 2000, epsilon 0.0009077786378036242 total_time 726.0\n",
      "episode 14019, reward 1774.0, memory_length 2000, epsilon 0.0009032510729591402 total_time 726.0\n",
      "episode 14029, reward 1764.0, memory_length 2000, epsilon 0.0008987460894385246 total_time 726.0\n",
      "episode 14039, reward 1758.0, memory_length 2000, epsilon 0.0008942635746169547 total_time 725.0\n",
      "episode 14049, reward 1437.0, memory_length 2000, epsilon 0.0008898034164313264 total_time 721.0\n",
      "episode 14059, reward 1793.0, memory_length 2000, epsilon 0.0008853655033774521 total_time 723.0\n",
      "episode 14069, reward 1775.0, memory_length 2000, epsilon 0.0008809497245072759 total_time 725.0\n",
      "episode 14079, reward 1908.0, memory_length 2000, epsilon 0.0008765559694260952 total_time 721.0\n",
      "episode 14089, reward 1820.0, memory_length 2000, epsilon 0.000872184128289804 total_time 725.0\n",
      "episode 14099, reward 1427.0, memory_length 2000, epsilon 0.0008678340918021465 total_time 730.0\n",
      "episode 14109, reward 1629.0, memory_length 2000, epsilon 0.0008635057512119837 total_time 721.0\n",
      "episode 14119, reward 1605.0, memory_length 2000, epsilon 0.0008591989983105755 total_time 722.0\n",
      "episode 14129, reward 1800.0, memory_length 2000, epsilon 0.0008549137254288751 total_time 721.0\n",
      "episode 14139, reward 1887.0, memory_length 2000, epsilon 0.0008506498254348365 total_time 725.0\n",
      "episode 14149, reward 1823.0, memory_length 2000, epsilon 0.0008464071917307392 total_time 731.0\n",
      "episode 14159, reward 1404.0, memory_length 2000, epsilon 0.0008421857182505188 total_time 726.0\n",
      "episode 14169, reward 1990.0, memory_length 2000, epsilon 0.0008379852994571187 total_time 726.0\n",
      "episode 14179, reward 1396.0, memory_length 2000, epsilon 0.00083380583033985 total_time 724.0\n",
      "episode 14189, reward 1837.0, memory_length 2000, epsilon 0.0008296472064117673 total_time 721.0\n",
      "episode 14199, reward 1701.0, memory_length 2000, epsilon 0.0008255093237070557 total_time 723.0\n",
      "episode 14209, reward 1836.0, memory_length 2000, epsilon 0.0008213920787784321 total_time 727.0\n",
      "episode 14219, reward 1514.0, memory_length 2000, epsilon 0.0008172953686945588 total_time 724.0\n",
      "episode 14229, reward 1758.0, memory_length 2000, epsilon 0.0008132190910374698 total_time 724.0\n",
      "episode 14239, reward 1384.0, memory_length 2000, epsilon 0.0008091631439000125 total_time 729.0\n",
      "episode 14249, reward 1848.0, memory_length 2000, epsilon 0.0008051274258832966 total_time 722.0\n",
      "episode 14259, reward 1880.0, memory_length 2000, epsilon 0.0008011118360941616 total_time 721.0\n",
      "episode 14269, reward 1688.0, memory_length 2000, epsilon 0.0007971162741426536 total_time 725.0\n",
      "episode 14279, reward 1950.0, memory_length 2000, epsilon 0.0007931406401395156 total_time 728.0\n",
      "episode 14289, reward 1694.0, memory_length 2000, epsilon 0.0007891848346936906 total_time 725.0\n",
      "episode 14299, reward 1632.0, memory_length 2000, epsilon 0.0007852487589098364 total_time 722.0\n",
      "episode 14309, reward 1468.0, memory_length 2000, epsilon 0.0007813323143858526 total_time 724.0\n",
      "episode 14319, reward 1778.0, memory_length 2000, epsilon 0.0007774354032104235 total_time 721.0\n",
      "episode 14329, reward 1453.0, memory_length 2000, epsilon 0.0007735579279605663 total_time 721.0\n",
      "episode 14339, reward 1625.0, memory_length 2000, epsilon 0.0007696997916991974 total_time 722.0\n",
      "episode 14349, reward 1772.0, memory_length 2000, epsilon 0.0007658608979727096 total_time 726.0\n",
      "episode 14359, reward 1734.0, memory_length 2000, epsilon 0.0007620411508085598 total_time 721.0\n",
      "episode 14369, reward 1844.0, memory_length 2000, epsilon 0.00075824045471287 total_time 721.0\n",
      "episode 14379, reward 1658.0, memory_length 2000, epsilon 0.0007544587146680395 total_time 724.0\n",
      "episode 14389, reward 1693.0, memory_length 2000, epsilon 0.0007506958361303699 total_time 726.0\n",
      "episode 14399, reward 1634.0, memory_length 2000, epsilon 0.0007469517250277031 total_time 725.0\n",
      "episode 14409, reward 1792.0, memory_length 2000, epsilon 0.0007432262877570657 total_time 729.0\n",
      "episode 14419, reward 1674.0, memory_length 2000, epsilon 0.0007395194311823318 total_time 729.0\n",
      "episode 14429, reward 2100.0, memory_length 2000, epsilon 0.0007358310626318943 total_time 722.0\n",
      "episode 14439, reward 1909.0, memory_length 2000, epsilon 0.0007321610898963471 total_time 729.0\n",
      "episode 14449, reward 1967.0, memory_length 2000, epsilon 0.0007285094212261808 total_time 734.0\n",
      "episode 14459, reward 1608.0, memory_length 2000, epsilon 0.0007248759653294883 total_time 723.0\n",
      "episode 14469, reward 1456.0, memory_length 2000, epsilon 0.0007212606313696831 total_time 721.0\n",
      "episode 14479, reward 1847.0, memory_length 2000, epsilon 0.0007176633289632272 total_time 724.0\n",
      "episode 14489, reward 1788.0, memory_length 2000, epsilon 0.0007140839681773742 total_time 721.0\n",
      "episode 14499, reward 1949.0, memory_length 2000, epsilon 0.0007105224595279177 total_time 729.0\n",
      "episode 14509, reward 1802.0, memory_length 2000, epsilon 0.0007069787139769558 total_time 726.0\n",
      "episode 14519, reward 1514.0, memory_length 2000, epsilon 0.0007034526429306651 total_time 724.0\n",
      "episode 14529, reward 1458.0, memory_length 2000, epsilon 0.0006999441582370858 total_time 732.0\n",
      "episode 14539, reward 1499.0, memory_length 2000, epsilon 0.0006964531721839179 total_time 724.0\n",
      "episode 14549, reward 1668.0, memory_length 2000, epsilon 0.0006929795974963283 total_time 722.0\n",
      "episode 14559, reward 1681.0, memory_length 2000, epsilon 0.0006895233473347682 total_time 723.0\n",
      "episode 14569, reward 1919.0, memory_length 2000, epsilon 0.0006860843352928048 total_time 727.0\n",
      "episode 14579, reward 1682.0, memory_length 2000, epsilon 0.0006826624753949572 total_time 721.0\n",
      "episode 14589, reward 1720.0, memory_length 2000, epsilon 0.0006792576820945501 total_time 729.0\n",
      "episode 14599, reward 1312.0, memory_length 2000, epsilon 0.0006758698702715732 total_time 724.0\n",
      "episode 14609, reward 1765.0, memory_length 2000, epsilon 0.0006724989552305546 total_time 724.0\n",
      "episode 14619, reward 1459.0, memory_length 2000, epsilon 0.0006691448526984429 total_time 731.0\n",
      "episode 14629, reward 1837.0, memory_length 2000, epsilon 0.0006658074788224999 total_time 724.0\n",
      "episode 14639, reward 1616.0, memory_length 2000, epsilon 0.0006624867501682045 total_time 721.0\n",
      "episode 14649, reward 1684.0, memory_length 2000, epsilon 0.0006591825837171684 total_time 726.0\n",
      "episode 14659, reward 1827.0, memory_length 2000, epsilon 0.0006558948968650576 total_time 721.0\n",
      "episode 14669, reward 2070.0, memory_length 2000, epsilon 0.0006526236074195298 total_time 722.0\n",
      "episode 14679, reward 1648.0, memory_length 2000, epsilon 0.0006493686335981781 total_time 723.0\n",
      "episode 14689, reward 1473.0, memory_length 2000, epsilon 0.0006461298940264879 total_time 722.0\n",
      "episode 14699, reward 1931.0, memory_length 2000, epsilon 0.0006429073077358008 total_time 725.0\n",
      "episode 14709, reward 1369.0, memory_length 2000, epsilon 0.000639700794161292 total_time 723.0\n",
      "episode 14719, reward 1586.0, memory_length 2000, epsilon 0.0006365102731399544 total_time 721.0\n",
      "episode 14729, reward 1403.0, memory_length 2000, epsilon 0.0006333356649085975 total_time 721.0\n",
      "episode 14739, reward 1577.0, memory_length 2000, epsilon 0.0006301768901018495 total_time 725.0\n",
      "episode 14749, reward 1410.0, memory_length 2000, epsilon 0.000627033869750176 total_time 724.0\n",
      "episode 14759, reward 1413.0, memory_length 2000, epsilon 0.0006239065252779041 total_time 721.0\n",
      "episode 14769, reward 1507.0, memory_length 2000, epsilon 0.0006207947785012593 total_time 722.0\n",
      "episode 14779, reward 1886.0, memory_length 2000, epsilon 0.0006176985516264101 total_time 727.0\n",
      "episode 14789, reward 1579.0, memory_length 2000, epsilon 0.0006146177672475235 total_time 722.0\n",
      "episode 14799, reward 1755.0, memory_length 2000, epsilon 0.0006115523483448293 total_time 726.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14809, reward 2012.0, memory_length 2000, epsilon 0.0006085022182826951 total_time 727.0\n",
      "episode 14819, reward 1908.0, memory_length 2000, epsilon 0.0006054673008077113 total_time 722.0\n",
      "episode 14829, reward 1830.0, memory_length 2000, epsilon 0.0006024475200467823 total_time 721.0\n",
      "episode 14839, reward 1405.0, memory_length 2000, epsilon 0.0005994428005052322 total_time 723.0\n",
      "episode 14849, reward 1517.0, memory_length 2000, epsilon 0.0005964530670649156 total_time 727.0\n",
      "episode 14859, reward 1697.0, memory_length 2000, epsilon 0.0005934782449823409 total_time 722.0\n",
      "episode 14869, reward 2035.0, memory_length 2000, epsilon 0.0005905182598868013 total_time 729.0\n",
      "episode 14879, reward 1663.0, memory_length 2000, epsilon 0.0005875730377785148 total_time 725.0\n",
      "episode 14889, reward 1559.0, memory_length 2000, epsilon 0.0005846425050267752 total_time 722.0\n",
      "episode 14899, reward 1596.0, memory_length 2000, epsilon 0.0005817265883681118 total_time 723.0\n",
      "episode 14909, reward 1691.0, memory_length 2000, epsilon 0.000578825214904456 total_time 722.0\n",
      "episode 14919, reward 1958.0, memory_length 2000, epsilon 0.00057593831210132 total_time 722.0\n",
      "episode 14929, reward 1536.0, memory_length 2000, epsilon 0.0005730658077859833 total_time 722.0\n",
      "episode 14939, reward 1415.0, memory_length 2000, epsilon 0.0005702076301456883 total_time 724.0\n",
      "episode 14949, reward 1623.0, memory_length 2000, epsilon 0.0005673637077258456 total_time 722.0\n",
      "episode 14959, reward 2065.0, memory_length 2000, epsilon 0.0005645339694282461 total_time 722.0\n",
      "episode 14969, reward 1780.0, memory_length 2000, epsilon 0.0005617183445092846 total_time 721.0\n",
      "episode 14979, reward 1914.0, memory_length 2000, epsilon 0.0005589167625781924 total_time 726.0\n",
      "episode 14989, reward 1776.0, memory_length 2000, epsilon 0.0005561291535952752 total_time 722.0\n",
      "episode 14999, reward 1663.0, memory_length 2000, epsilon 0.0005533554478701629 total_time 727.0\n",
      "21402.952618598938\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "score_tracked = []\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "\n",
    "    done = False\n",
    "    score = 0\n",
    "    track_reward = False\n",
    "\n",
    "    env = CabDriver()\n",
    "    action_space, state_space, state = env.reset()\n",
    "    # Save the initial state\n",
    "    initial_state = env.state_init\n",
    "\n",
    "\n",
    "    total_time = 0  \n",
    "    while not done:\n",
    "        # 1. Get a list of the ride requests driver got.\n",
    "        possible_actions_indices, actions = env.requests(state)\n",
    "        # 2. Pick epsilon-greedy action from possible actions for the current state.\n",
    "        action = agent.get_action(state, possible_actions_indices, actions)\n",
    "\n",
    "        # 3. Evaluate your reward and next state\n",
    "        reward, next_state, step_time = env.step(state, env.action_space[action], Time_matrix)\n",
    "        # 4. Total time driver rode in this episode\n",
    "        total_time += step_time\n",
    "        if (total_time > episode_time):\n",
    "            # if ride does not complete in stipulated time skip\n",
    "            done = True\n",
    "        else:\n",
    "            # 5. Append the experience to the memory\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            # 6. Train the model by calling function agent.train_model\n",
    "            agent.train_model()\n",
    "            # 7. Keep a track of rewards, Q-values, loss\n",
    "            score += reward\n",
    "            state = next_state\n",
    "\n",
    "    # store total reward obtained in this episode\n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "    \n",
    "    # epsilon decay\n",
    "    agent.epsilon = (1 - 0.00001) * np.exp(agent.epsilon_decay * episode)\n",
    "\n",
    "    # every 10 episodes:\n",
    "    if ((episode + 1) % 10 == 0):\n",
    "        print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3} total_time {4}\".format(episode,\n",
    "                                                                         score,\n",
    "                                                                         len(agent.memory),\n",
    "                                                                         agent.epsilon, total_time))\n",
    "    # Save the Q_value of the state, action pair we are tracking\n",
    "    if ((episode + 1) % 5 == 0):\n",
    "        agent.save_tracking_states()\n",
    "\n",
    "    # Total rewards per episode\n",
    "    score_tracked.append(score)\n",
    "\n",
    "    if(episode % 1000 == 0):\n",
    "        print(\"Saving Model {}\".format(episode))\n",
    "        agent.save(name=\"model_weights.pkl\")\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "xaxis = np.asarray(range(0, len(agent.states_tracked)))\n",
    "plt.scatter(xaxis,np.asarray(agent.states_tracked))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
